{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f4c909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                       post/keyword  \\\n",
      "0  28987  Taiping Perak Banjir 28/08/2022 #azrulazim352 ...   \n",
      "1  28988  Taiping Perak Banjir 28/08/2022 #azrulazim352 ...   \n",
      "2  28989  Taiping Perak Banjir 28/08/2022 #azrulazim352 ...   \n",
      "3  28990  banjir simpang 4 benoni #banjir2022 Publish: 1...   \n",
      "4  28991  banjir simpang 4 benoni #banjir2022 Publish: 1...   \n",
      "\n",
      "                                       comment/tweet      username like count  \\\n",
      "0        sius la awk..bnjir sana..kwn xckp ape pon??  33d2a31d-c13          1   \n",
      "1  srikota, taman sg mas, air kuning semua banjir...  61957789-224          0   \n",
      "2  massyaallah.. . dasyatnya bnjir kali nie kawan...  cffa43d1-936          2   \n",
      "3                               Simpang p papar kan?  c3128b6f-2e5          2   \n",
      "4                       nasib baik lah sempat limpas  813bbc92-ca2          1   \n",
      "\n",
      "     replied to reply count 2nd level comment/ reply time created  \\\n",
      "0           ---           1                       No    29/8/2022   \n",
      "1  33d2a31d-c13         ---                      Yes    29/8/2022   \n",
      "2           ---           1                       No    29/8/2022   \n",
      "3           ---           0                       No      2d ago    \n",
      "4           ---           0                       No      2d ago    \n",
      "\n",
      "  majority_sent majority_sarc lang_id  \n",
      "0       neutral       notsarc      my  \n",
      "1       neutral       notsarc      my  \n",
      "2      negative       notsarc      my  \n",
      "3       neutral       notsarc      my  \n",
      "4      positive       notsarc      my  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"annotated_bicodemix_publicsa_v2.csv\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c0dfe24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                  text  sarcasm sentiment\n",
       " 157  \"This parking lot is not a new news btw. It ha...  notsarc  negative\n",
       " 158  \"GLOBAL WARMING LA. GOD ASKS YOU TO SOLVE IT. ...     sarc  negative\n",
       " 365  \"??????????????am so happy to see all this hap...  notsarc  negative\n",
       " 491  \"Why no one Question our Billions dollars SMAR...     sarc  negative\n",
       " 599  \"banjir kilat. happens when govt don't improve...  notsarc  negative,\n",
       " (624, 3))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['lang_id'] == 'en') & (df['comment/tweet'].str.split().str.len() >= 10)]\n",
    "df = df[['comment/tweet', 'majority_sarc', 'majority_sent']]\n",
    "df.rename(columns={\"majority_sarc\": \"sarcasm\", \"majority_sent\": \"sentiment\", \"comment/tweet\": \"text\"}, inplace=True)\n",
    "mask = ~(\n",
    "    df['text'].str.startswith('\"') &\n",
    "    df['text'].str.endswith('\"')\n",
    ")\n",
    "\n",
    "df.loc[mask, 'text'] = '\"' + df.loc[mask, 'text'] + '\"'\n",
    "\n",
    "\n",
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "564a6e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 499\n",
      "Validation set size: 125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {train_df.shape[0]}\")\n",
    "print(f\"Validation set size: {val_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3cc7825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>\"Was there any effort for stopping the fire? C...</td>\n",
       "      <td>notsarc</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8090</th>\n",
       "      <td>\"Climate change are a scary thing. The Earth a...</td>\n",
       "      <td>notsarc</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>\"not surprising at all...it happened around th...</td>\n",
       "      <td>sarc</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>\"My hearts are to all the doctors. What’s wron...</td>\n",
       "      <td>sarc</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>\"But contract, with no aid from government to ...</td>\n",
       "      <td>notsarc</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sarcasm sentiment\n",
       "8348  \"Was there any effort for stopping the fire? C...  notsarc  negative\n",
       "8090  \"Climate change are a scary thing. The Earth a...  notsarc   neutral\n",
       "737   \"not surprising at all...it happened around th...     sarc  positive\n",
       "3751  \"My hearts are to all the doctors. What’s wron...     sarc  negative\n",
       "3801  \"But contract, with no aid from government to ...  notsarc  negative"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab3bed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "train_df.to_csv(\"train_SS.csv\", index=False, quoting=csv.QUOTE_NONE, escapechar='\\\\', sep=';')\n",
    "val_df.to_csv(\"valid_SS.csv\", index=False, quoting=csv.QUOTE_NONE, escapechar='\\\\', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea973a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataset_bicodemix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BicodemixDataSet\n\u001b[0;32m----> 2\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mBicodemixDataSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_SS.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Polito/Deep natural language processing/Project/dataset/bicodemix/dataset_bicodemix.py:22\u001b[0m, in \u001b[0;36mBicodemixDataSet.__init__\u001b[0;34m(self, root_folder, file_name, classes, tokenizer, header, min_length, max_length, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Polito/Deep natural language processing/Project/dataset/bicodemix/dataset_bicodemix.py:35\u001b[0m, in \u001b[0;36mBicodemixDataSet._load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m text, sarcasm_label, sentiment_label \u001b[38;5;241m=\u001b[39m row\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_length:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "from dataset_bicodemix import BicodemixDataSet\n",
    "train_ds = BicodemixDataSet(\n",
    "    root_folder='', file_name='train_SS.csv',\n",
    "    classes=['0', '1'],\n",
    "    tokenizer=None,\n",
    "    min_length=1,\n",
    "    max_length=200\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
