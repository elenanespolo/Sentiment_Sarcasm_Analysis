{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# per trainare su Colab, impostare TRAIN_COLAB = True\n",
        "# altrimenti in locale mettere TRAIN_COLAB = False\n",
        "\n",
        "TRAIN_COLAB = True\n",
        "\n",
        "if TRAIN_COLAB:\n",
        "    !git clone https://github.com/elenanespolo/Sentiment_Sarcasm_Analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBc2zrlphNWr",
        "outputId": "b2d023e2-acf6-4ad3-d43e-58ac7bc52e0c"
      },
      "id": "YBc2zrlphNWr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Sentiment_Sarcasm_Analysis' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update Colab folder after a push in the repository\n",
        "\n",
        "%cd Sentiment_Sarcasm_Analysis\n",
        "!git pull\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qECGVaG0hbcy",
        "outputId": "ade0dbfe-27b6-4205-f7f8-fc5f47ed5b05"
      },
      "id": "qECGVaG0hbcy",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Sentiment_Sarcasm_Analysis\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WeiChengTseng/Pytorch-PCGrad\n",
        "!mv Pytorch-PCGrad pcgrad_repo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKnn-MKupiXD",
        "outputId": "17d8e75d-fca2-4e87-e548-c8bf7a031489"
      },
      "id": "wKnn-MKupiXD",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pytorch-PCGrad'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 133 (delta 24), reused 22 (delta 22), pack-reused 105 (from 1)\u001b[K\n",
            "Receiving objects: 100% (133/133), 563.81 KiB | 2.78 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b3fb6e87",
      "metadata": {
        "id": "b3fb6e87"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import transformers\n",
        "\n",
        "if TRAIN_COLAB:\n",
        "    from Sentiment_Sarcasm_Analysis.dataset.besstie import dataset_besstie\n",
        "    root_folder = \"Sentiment_Sarcasm_Analysis/dataset/besstie/\"\n",
        "else:\n",
        "    from dataset.besstie import dataset_besstie\n",
        "    root_folder = \"dataset/besstie/\"\n",
        "\n",
        "splits = {'train': 'train_SS.csv', 'validation': 'valid_SS.csv'}\n",
        "if not os.path.exists(root_folder):\n",
        "    os.makedirs(root_folder)\n",
        "if not os.path.exists(os.path.join(root_folder, splits[\"train\"])) or not os.path.exists(os.path.join(root_folder, splits[\"validation\"])):\n",
        "    print(\"Downloading BESSTIE dataset...\")\n",
        "    # Login using e.g. `huggingface-cli login` to access this dataset\n",
        "    df = pd.read_csv(\"hf://datasets/unswnlporg/BESSTIE/\" + splits[\"train\"])\n",
        "    df.to_csv(os.path.join(root_folder, splits[\"train\"]), index=False)\n",
        "    df = pd.read_csv(\"hf://datasets/unswnlporg/BESSTIE/\" + splits[\"validation\"])\n",
        "    df.to_csv(os.path.join(root_folder, splits[\"validation\"]), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "470d7461",
      "metadata": {
        "id": "470d7461"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6f57f88e",
      "metadata": {
        "id": "6f57f88e",
        "outputId": "298c53c3-fe9d-46e8-f3c6-8fc66a27bc1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sarcasm  sentiment\n",
            "0     2315       2361\n",
            "1      808        762\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "#TODO: add ability to choose validation subcategory of the dataset\n",
        "dataset_CFG = {\n",
        "    'dataset_name': 'BESSTIE',\n",
        "    'task': 'Sentiment-Sarcasm',\n",
        "    'variety': 'en-UK',\n",
        "    'source': 'Reddit',\n",
        "    'classes': ['0', '1']\n",
        "}\n",
        "CFG = {\n",
        "    'lr': 2e-5,\n",
        "    'epochs': 8,\n",
        "    'batch_size': 8,\n",
        "    'max_length': 200,\n",
        "    'min_length': 1,\n",
        "    **dataset_CFG,\n",
        "    'model_name': 'bert-base-uncased',\n",
        "    'classification_head': 'cross_talk_conv', # 'linear' or 'conv' or 'lstm' or 'multi_task_conv' or 'cross_talk_conv'\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(root_folder, splits['train']))\n",
        "if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "    labels_count = pd.concat([df_train['sarcasm'].value_counts().sort_index(),df_train['sentiment'].value_counts().sort_index()], axis=1).set_axis(labels=['sarcasm', 'sentiment'], axis=1)\n",
        "else:\n",
        "    labels_count = df_train[\"label\"].value_counts().sort_index()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(labels_count)\n",
        "print(\"Using device:\", device)\n",
        "set_seed(CFG['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e508f6ad",
      "metadata": {
        "id": "e508f6ad"
      },
      "outputs": [],
      "source": [
        "class MultiKernelConvHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        num_labels: int,\n",
        "        kernel_sizes=(2, 3, 5),\n",
        "        dropout=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList([\n",
        "            torch.nn.Conv1d(\n",
        "                in_channels=input_size,\n",
        "                out_channels=hidden_size,\n",
        "                kernel_size=k,\n",
        "                padding=k // 2\n",
        "            )\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.classifier = torch.nn.Linear(\n",
        "            hidden_size * len(kernel_sizes),\n",
        "            num_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, H, L)\n",
        "        conv_outputs = []\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = self.activation(conv(x))      # (B, C, L)\n",
        "            h = self.pool(h).squeeze(-1)       # (B, C)\n",
        "            conv_outputs.append(h)\n",
        "\n",
        "        x = torch.cat(conv_outputs, dim=1)    # (B, C * num_kernels)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "class ConvClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, num_labels: int, linear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        if linear:\n",
        "            self.conv = torch.nn.Sequential(\n",
        "                torch.nn.Conv1d(\n",
        "                    in_channels=input_size,\n",
        "                    out_channels=hidden_size,\n",
        "                    kernel_size=3,\n",
        "                    padding=1\n",
        "                ),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.AdaptiveAvgPool1d(1),  # (B, hidden_size, 1)\n",
        "                torch.nn.Flatten(),             # (B, hidden_size)\n",
        "                torch.nn.Linear(hidden_size, num_labels)\n",
        "            )\n",
        "        else:\n",
        "            self.conv = torch.nn.Sequential(\n",
        "                torch.nn.Conv1d(\n",
        "                    in_channels=input_size,\n",
        "                    out_channels=hidden_size,\n",
        "                    kernel_size=3,\n",
        "                    padding=1\n",
        "                ),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.AdaptiveAvgPool1d(1),  # (B, hidden_size, 1)\n",
        "                torch.nn.Flatten()              # (B, hidden_size)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class MultiTaskConvHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        num_sentiment_labels: int,\n",
        "        num_sarcasm_labels: int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sentiment_head = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_sentiment_labels\n",
        "        )\n",
        "\n",
        "        self.sarcasm_head = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_sarcasm_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        \"\"\"\n",
        "        sequence_output: last_hidden_state from BERT\n",
        "        shape: (batch, seq_len, hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        sentiment_logits = self.sentiment_head(sequence_output)\n",
        "        sarcasm_logits = self.sarcasm_head(sequence_output)\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": sentiment_logits,\n",
        "            \"sarcasm\": sarcasm_logits\n",
        "        }\n",
        "\n",
        "class CrossTalkHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        conv_hidden_size,\n",
        "        num_sentiment_labels,\n",
        "        num_sarcasm_labels\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=conv_hidden_size,\n",
        "            num_labels = 0,\n",
        "            linear = False\n",
        "        )\n",
        "\n",
        "        # task-specific embeddings\n",
        "        self.sentiment_embed = torch.nn.Linear(\n",
        "            conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "        self.sarcasm_embed = torch.nn.Linear(\n",
        "            conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "\n",
        "        # cross-talk layers\n",
        "        self.sentiment_fuse = torch.nn.Linear(\n",
        "            2 * conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "        self.sarcasm_fuse = torch.nn.Linear(\n",
        "            2 * conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "\n",
        "        self.sentiment_out = torch.nn.Linear(\n",
        "            conv_hidden_size, num_sentiment_labels\n",
        "        )\n",
        "        self.sarcasm_out = torch.nn.Linear(\n",
        "            conv_hidden_size, num_sarcasm_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        shared = self.encoder(sequence_output)\n",
        "\n",
        "        # first linear layer\n",
        "        sent_feat = self.sentiment_embed(shared)\n",
        "        sarc_feat = self.sarcasm_embed(shared)\n",
        "\n",
        "        # cross-talk\n",
        "        sent_feat = self.sentiment_fuse(\n",
        "            torch.cat([sent_feat, sarc_feat], dim=-1)\n",
        "        )\n",
        "        sarc_feat = self.sarcasm_fuse(\n",
        "            torch.cat([sarc_feat, sent_feat], dim=-1)\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": self.sentiment_out(sent_feat),\n",
        "            \"sarcasm\": self.sarcasm_out(sarc_feat)\n",
        "        }\n",
        "\n",
        "def get_tokenizer_and_model(model_name:str):\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    model = transformers.AutoModel.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "def get_classification_head(method: str, input_size:int, hidden_size: int, num_labels: int):\n",
        "    if method == \"linear\":\n",
        "        return torch.nn.Linear(input_size, num_labels)\n",
        "    elif method == \"conv\":\n",
        "        return ConvClassificationHead(input_size, hidden_size, num_labels)\n",
        "    elif method == \"lstm\":\n",
        "        return torch.nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "    elif method == \"multi_conv\":\n",
        "        return MultiKernelConvHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_labels,\n",
        "            kernel_sizes=(2, 3, 5),\n",
        "            num_channels=128,\n",
        "            dropout=0.1\n",
        "        )\n",
        "    elif method == 'multi_task_conv':\n",
        "        return MultiTaskConvHead(input_size, hidden_size, num_labels, num_labels)\n",
        "    elif method == 'cross_talk_conv':\n",
        "        return CrossTalkHead(input_size, hidden_size, num_labels, num_labels)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown classification head method: {method}\")\n",
        "\n",
        "\n",
        "class MyClassifier(torch.nn.Module):\n",
        "    def __init__(self, base_model_name, classification_head_name, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tokenizer, self.base_model = get_tokenizer_and_model(base_model_name)\n",
        "        self.hidden_size = self.base_model.config.hidden_size\n",
        "        self.dropout = torch.nn.Dropout(self.base_model.config.hidden_dropout_prob)\n",
        "\n",
        "        self.classification_head_name = classification_head_name\n",
        "\n",
        "        self.classification_head = get_classification_head(\n",
        "            classification_head_name, self.hidden_size, self.hidden_size, num_labels\n",
        "        )\n",
        "\n",
        "        if classification_head_name == \"lstm\":\n",
        "            self.output_layer = torch.nn.Linear(self.hidden_size*2, num_labels)\n",
        "\n",
        "    def get_tokenizer(self) -> transformers.PreTrainedTokenizer:\n",
        "        return self.tokenizer\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = self.base_model(**inputs)\n",
        "        sequence = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        if self.classification_head_name == \"linear\":\n",
        "            cls_rep = sequence[:, 0, :]\n",
        "            logits = self.classification_head(cls_rep)\n",
        "\n",
        "        elif self.classification_head_name == \"conv\":\n",
        "            # x: (batch, seq_len, hidden_size)\n",
        "            x = sequence.transpose(1, 2)  # -> (batch, hidden_size, seq_len)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        elif self.classification_head_name == \"lstm\":\n",
        "            lstm_out, _ = self.classification_head(sequence)\n",
        "            cls_rep = lstm_out[:, 0, :]\n",
        "            logits = self.output_layer(cls_rep)\n",
        "\n",
        "        elif self.classification_head_name == 'multi_conv':\n",
        "            ## TO-DO: implement\n",
        "            logits = None\n",
        "\n",
        "        elif self.classification_head_name == 'multi_task_conv':\n",
        "            ## TO-DO: implement\n",
        "            logits = None\n",
        "\n",
        "        elif self.classification_head_name == 'cross_talk_conv':\n",
        "            x = sequence.transpose(1, 2)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bc87a7ea",
      "metadata": {
        "id": "bc87a7ea"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    val_sarc_acc = 0.0\n",
        "    val_sent_acc = 0.0\n",
        "    val_sarc_loss = 0.0\n",
        "    val_sent_loss = 0.0\n",
        "    for batch in val_loader:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "        local_labels = batch['label'].to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "            sarcasm_criterion, sentiment_criterion = criterion\n",
        "            sarc_loss = sarcasm_criterion(outputs['sarcasm'], local_labels[:,0])\n",
        "            sent_loss = sentiment_criterion(outputs['sentiment'], local_labels[:,1])\n",
        "\n",
        "            _, preds_sarc = torch.max(outputs['sarcasm'], dim=1)\n",
        "            _, preds_sent = torch.max(outputs['sentiment'], dim=1)\n",
        "\n",
        "            val_sarc_acc += torch.sum(preds_sarc == local_labels[:,0]).item()\n",
        "            val_sent_acc += torch.sum(preds_sent == local_labels[:,1]).item()\n",
        "\n",
        "            val_sarc_loss += sarc_loss.item()\n",
        "            val_sent_loss += sent_loss.item()\n",
        "\n",
        "            return val_sarc_loss / len(val_loader), val_sarc_acc / len(val_loader.dataset), val_sent_loss / len(val_loader), val_sent_acc / len(val_loader.dataset)\n",
        "        else:\n",
        "            loss = criterion(outputs, local_labels)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            val_acc += torch.sum(preds == local_labels).item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            return val_loss / len(val_loader), val_acc / len(val_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "47a57619",
      "metadata": {
        "id": "47a57619",
        "outputId": "c57ff3e6-8224-425c-af99-96821d2caf1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melena-nespolo02\u001b[0m (\u001b[33melena-nespolo02-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260102_230006-1eqqdziq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/1eqqdziq' target=\"_blank\">Test elena cross talk</a></strong> to <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis' target=\"_blank\">https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/1eqqdziq' target=\"_blank\">https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/1eqqdziq</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import wandb\n",
        "run_name = \"Test elena cross talk\"\n",
        "# run_name = None\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=\"elena-nespolo02-politecnico-di-torino\",\n",
        "    project=\"Figurative Analysis\",\n",
        "    name=run_name,\n",
        "    config=CFG,\n",
        "    tags=[CFG['dataset_name'], CFG['task'], CFG['model_name']]\n",
        ")\n",
        "\n",
        "# 1f6fd3931919776776756ae7b17e69da4d5c6c3d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a7b59a",
      "metadata": {
        "id": "c9a7b59a",
        "outputId": "5d33b723-b00f-44c1-e41a-5aa40918160f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 16/90 [10:21<46:38, 37.82s/it]"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "from pcgrad_repo.pcgrad import PCGrad\n",
        "\n",
        "model_name = CFG['model_name']\n",
        "\n",
        "tokenizer, model = get_tokenizer_and_model(model_name)\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# load classifier model\n",
        "# model = transformers.BertForSequenceClassification.from_pretrained(\n",
        "#     model_name,\n",
        "#     num_labels=2\n",
        "# ).to(device)\n",
        "\n",
        "model = MyClassifier(\n",
        "    base_model_name=model_name,\n",
        "    classification_head_name=CFG['classification_head'],\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "train_ds = dataset_besstie.BesstieDataSet(\n",
        "    root_folder=root_folder,\n",
        "    file_name=splits['train'],\n",
        "    classes=dataset_CFG['classes'],\n",
        "    tokenizer=tokenizer,\n",
        "    min_length=CFG['min_length'],\n",
        "    max_length=CFG['max_length'],\n",
        "    variety=CFG['variety'],\n",
        "    source=CFG['source'],\n",
        "    task=CFG['task']\n",
        ")\n",
        "\n",
        "val_ds = dataset_besstie.BesstieDataSet(\n",
        "    root_folder=root_folder,\n",
        "    file_name=splits['validation'],\n",
        "    classes=dataset_CFG['classes'],\n",
        "    tokenizer=tokenizer,\n",
        "    min_length=CFG['min_length'],\n",
        "    max_length=CFG['max_length'],\n",
        "    variety=CFG['variety'],\n",
        "    source=CFG['source'],\n",
        "    task=CFG['task']\n",
        ")\n",
        "\n",
        "if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "    optimizer = PCGrad(torch.optim.Adam(model.parameters()))\n",
        "    sarcasm_criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count['sarcasm'].values/sum(labels_count['sarcasm']), dtype=torch.float).to(device)\n",
        "    )\n",
        "    sentiment_criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count['sentiment'].values/sum(labels_count['sentiment']), dtype=torch.float).to(device)\n",
        "    )\n",
        "    losses = [sarcasm_criterion, sentiment_criterion] # a list of per-task losses\n",
        "else:\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
        "    criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count.values/sum(labels_count), dtype=torch.float).to(device)\n",
        "    )\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "#TODO: gradient accumulation to reduce memory usage?\n",
        "# accumulation_steps = 4  # Effective batch size = batch_size * accumulation_steps\n",
        "# for i, batch in enumerate(train_dataloader):\n",
        "#     outputs = model(**batch)\n",
        "#     loss = outputs.loss / accumulation_steps\n",
        "#     loss.backward()\n",
        "#     if (i + 1) % accumulation_steps == 0:\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()\n",
        "#         model.zero_grad()\n",
        "\n",
        "for epoch in range(CFG['epochs']):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_sarc_loss = 0.0\n",
        "    train_sent_loss = 0.0\n",
        "    print(f\"Epoch {epoch+1}/{CFG['epochs']}\")\n",
        "\n",
        "    pbar = tqdm.tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "\n",
        "        local_labels = batch['label'].to(device)\n",
        "        outputs = model(inputs)\n",
        "        if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "            # print(len(local_labels), len(outputs))\n",
        "            # 8 2\n",
        "            # print(type(local_labels), type(outputs))\n",
        "            # <class 'torch.Tensor'> <class 'dict'>\n",
        "            # print(local_labels.shape, outputs.keys(), outputs['sarcasm'].shape, outputs['sentiment'].shape)\n",
        "            # torch.Size([8, 2]) dict_keys(['sentiment', 'sarcasm']) torch.Size([8, 2]) torch.Size([8, 2])\n",
        "            sarc_loss = sarcasm_criterion(outputs['sarcasm'], local_labels[:,0])\n",
        "            sent_loss = sentiment_criterion(outputs['sentiment'], local_labels[:,1])\n",
        "\n",
        "            optimizer.pc_backward([sarc_loss, sent_loss])\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_sarc_loss += sarc_loss.item()\n",
        "            train_sent_loss += sent_loss.item()\n",
        "\n",
        "        else:\n",
        "            loss = criterion(outputs, local_labels)\n",
        "            print(len(local_labels), len(outputs))\n",
        "            print(type(local_labels), type(outputs))\n",
        "            # <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "            print(local_labels.shape, outputs.shape)\n",
        "            # torch.Size([8]) torch.Size([8, 2])\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "    val_sarc_loss, val_sarc_acc, val_sent_loss, val_sent_acc = validate(model, val_loader, [sarcasm_criterion, sentiment_criterion], device)\n",
        "\n",
        "    if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "        epoch_sarc_loss = train_sarc_loss / len(train_loader)\n",
        "        epoch_sent_loss = train_sent_loss / len(train_loader)\n",
        "        # run.log({\"train_sarc_loss\": epoch_sarc_loss, \"train_sent_loss\": epoch_sent_loss, \"val_sarc_loss\": val_sarc_loss, \"val_sarc_acc\": val_sarc_acc, \"val_sent_loss\": val_sent_loss, \"val_sent_acc\": val_sent_acc})\n",
        "        print(f\"Training Sarcasm Loss: {epoch_sarc_loss:.4f}\")\n",
        "        print(f\"Training Sentiment Loss: {epoch_sent_loss:.4f}\")\n",
        "        print(f\"Validation Sarcasm Loss: {val_sarc_loss:.4f}\")\n",
        "        print(f\"Validation Sentiment Loss: {val_sent_loss:.4f}\")\n",
        "        print(f\"Validation Sarcasm Accuracy: {val_sarc_acc:.4f}\")\n",
        "        print(f\"Validation Sentiment Accuracy: {val_sent_acc:.4f}\")\n",
        "    else:\n",
        "        epoch_loss = train_loss / len(train_loader)\n",
        "        # run.log({\"train_loss\": epoch_loss, \"val_loss\": val_loss, \"val_acc\": val_acc})\n",
        "        print(f\"Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef757b0",
      "metadata": {
        "id": "7ef757b0",
        "outputId": "6f294466-5227-496e-9c92-e10cf79853e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test elena</strong> at: <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/77joevk1' target=\"_blank\">https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/77joevk1</a><br> View project at: <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis' target=\"_blank\">https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260102_080134-77joevk1/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}