{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "MOKwcP23xNii",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOKwcP23xNii",
        "outputId": "d299289d-67d8-4a56-da6c-c7b19cf9b60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Sentiment_Sarcasm_Analysis'...\n",
            "remote: Enumerating objects: 290, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 290 (delta 20), reused 18 (delta 11), pack-reused 255 (from 1)\u001b[K\n",
            "Receiving objects: 100% (290/290), 17.45 MiB | 12.83 MiB/s, done.\n",
            "Resolving deltas: 100% (153/153), done.\n",
            "Filtering content: 100% (11/11), 27.24 MiB | 16.71 MiB/s, done.\n",
            "/content/Sentiment_Sarcasm_Analysis\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/elenanespolo/Sentiment_Sarcasm_Analysis\n",
        "\n",
        "%cd Sentiment_Sarcasm_Analysis\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QSbdm5uA1ifz",
      "metadata": {
        "collapsed": true,
        "id": "QSbdm5uA1ifz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import transformers\n",
        "import tqdm\n",
        "from transformers import BertConfig, BertModel, BertTokenizer\n",
        "from transformers.models.bert.modeling_bert import BertLayer, BertEncoder\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions\n",
        "\n",
        "pcgrad_repo = \"./pcgrad_repo\"\n",
        "if not os.path.exists('./pcgrad_repo'):\n",
        "    !git clone https://github.com/WeiChengTseng/Pytorch-PCGrad\n",
        "    !mv Pytorch-PCGrad pcgrad_repo\n",
        "from pcgrad_repo.pcgrad import PCGrad\n",
        "\n",
        "!pip install bitsandbytes\n",
        "# quantization dependency (may need other dependencies that i forgot)\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, TaskType # LoRA imports (may need to add the pip install)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18aa3c59",
      "metadata": {
        "id": "18aa3c59"
      },
      "source": [
        "# Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "YBc2zrlphNWr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBc2zrlphNWr",
        "outputId": "4f7e4259-d43c-482c-b903-9adecd91f36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training in multitask mode.\n",
            "Using linear classification head (single task head) for multi-task learning. Aborting...\n",
            "Training with min_length=1 and max_length=200\n",
            "Quantization and LoRA configurations set.\n",
            "Run name is: bicodemix_linear_spatten\n"
          ]
        }
      ],
      "source": [
        "ENABLE_WANDB = False\n",
        "training_dataset_name = 'bicodemix'  # 'BESSTIE' or 'yelp' or 'bicodemix' or 'twitter'\n",
        "\n",
        "use_decoder = False  # if True use decoder otherwise use classification head on top of encoder\n",
        "\n",
        "use_spAtten = True # if True ...\n",
        "\n",
        "#NOTE: sentiment always first in 'task' field (index 0), sarcasm second (index 1) where not in dictionary\n",
        "#NOTE: task always lowercase, but check is always done\n",
        "#NOTE: class '0' (negative) always first in classes list (index 0), class '1' (positive) second (index 1), etc.\n",
        "#NOTE: if a task is not present, its classes list is empty (lenght of 0 not None)\n",
        "#NOTE: BESSTIE dataset apply filter base on value of 'task', 'variety' and 'source' fields,\n",
        "# if None, no filter applied for that field, only sample with correct values for that field are kept\n",
        "# if task is 'sentiment' only sample with at least sentiment labels are kept,\n",
        "# if 'sarcasm', only samples with at least sarcasm labels are kept\n",
        "# EXAMPLE: task = 'sentiment', variety = 'en-IN', source = 'Reddit' means:\n",
        "# keep only samples with sentiment labels not nan, variety 'en-IN' and source 'Reddit'\n",
        "\n",
        "#TODO: check yelp dataset if compatible\n",
        "#TODO: implement outomatic way to set min_length and max_length based on dataset statistics\n",
        "#TODO: implement for bicodemix selection of task other than sarcasm-sentiment\n",
        "train_dataset_CFGs = {\n",
        "    'BESSTIE':{\n",
        "        'dataset_name': 'BESSTIE',\n",
        "        'root_folder': './dataset/besstie',\n",
        "        'file_name': 'train_SS_with_nan.csv',\n",
        "        'classes': {\n",
        "            'sentiment': ['0', '1'],\n",
        "            'sarcasm': ['0', '1'],\n",
        "        },\n",
        "        'task': 'sentiment',\n",
        "        'variety': 'en-IN',\n",
        "        'source': 'Reddit',\n",
        "    },\n",
        "    'yelp': {\n",
        "        'dataset_name': 'yelp',\n",
        "        'root_folder': './dataset/yelp',\n",
        "        'file_name': 'yelp_filtered_reviews.csv',\n",
        "        'classes': {\n",
        "            'sentiment': ['useful', 'funny', 'cool'],\n",
        "            'sarcasm': [],\n",
        "        },\n",
        "        'task': 'sentiment',\n",
        "    },\n",
        "    'bicodemix': {\n",
        "        'dataset_name': 'bicodemix',\n",
        "        'root_folder': './dataset/bicodemix',\n",
        "        'file_name': 'train_SS.csv',\n",
        "        'classes': {\n",
        "            'sentiment': ['0', '1', '2'],\n",
        "            'sarcasm': ['0', '1'],\n",
        "        },\n",
        "        'task': 'sarcasm-sentiment',\n",
        "    },\n",
        "    'bicodemix_sarcasm': {\n",
        "        'dataset_name': 'bicodemix',\n",
        "        'root_folder': './dataset/bicodemix',\n",
        "        'file_name': 'train_SS.csv',\n",
        "        'classes': {\n",
        "            'sentiment': [],\n",
        "            'sarcasm': ['0', '1'],\n",
        "        },\n",
        "        'task': 'sarcasm',\n",
        "    },\n",
        "    'bicodemix_sentiment': {\n",
        "        'dataset_name': 'bicodemix',\n",
        "        'root_folder': './dataset/bicodemix',\n",
        "        'file_name': 'train_SS.csv',\n",
        "        'classes': {\n",
        "            'sentiment': ['0', '1', '2'],\n",
        "            'sarcasm': [],\n",
        "        },\n",
        "        'task': 'sentiment',\n",
        "    },\n",
        "    'twitter': {\n",
        "        'dataset_name': 'twitter',\n",
        "        'root_folder': './dataset/twitter',\n",
        "        'file_name': 'twitter_sentiment_analysis.csv',\n",
        "        'classes': {\n",
        "            'sentiment': ['Negative', 'Positive'],\n",
        "            'sarcasm': [],\n",
        "        },\n",
        "        'task': 'sentiment',\n",
        "    }\n",
        "}\n",
        "\n",
        "valid_dataset_CFG = {\n",
        "    'dataset_name': 'BESSTIE',\n",
        "    'root_folder': './dataset/besstie',\n",
        "    'file_name': 'valid_SS_with_nan.csv',\n",
        "    'classes': {\n",
        "        'sentiment': ['0', '1'],\n",
        "        'sarcasm': ['0', '1'],\n",
        "    },\n",
        "    'task': train_dataset_CFGs[training_dataset_name]['task'],\n",
        "    'variety': None,\n",
        "    'source': None,\n",
        "}\n",
        "\n",
        "# TODO: validate parameters\n",
        "QUANTIZATION_CFG = {\n",
        "    'load_in_4bit': True,\n",
        "    'bnb_4bit_quant_type': \"nf4\",\n",
        "    'bnb_4bit_compute_dtype': torch.float16,\n",
        "}\n",
        "\n",
        "# TODO: validate parameters\n",
        "LORA_CFG = {\n",
        "    'r': 16,\n",
        "    'lora_alpha': 32,\n",
        "    'target_modules': [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    'lora_dropout': 0.1,\n",
        "    'bias': \"none\",\n",
        "    'task_type': TaskType.CAUSAL_LM\n",
        "}\n",
        "\n",
        "CFG = {\n",
        "    'lr': 2e-5,\n",
        "    'start_epoch': 0,\n",
        "    'epochs': 30,\n",
        "    'batch_size': 8,\n",
        "    'max_length': 200,\n",
        "    'min_length': 1,\n",
        "    \"train_dataset_CFG\": train_dataset_CFGs[training_dataset_name],\n",
        "    \"valid_dataset_CFG\": valid_dataset_CFG,\n",
        "    'model_name': 'bert-base-uncased',\n",
        "    'classification_head': 'linear', # ['linear', 'conv', 'lstm', 'multi_task_conv', 'cross_talk_conv']\n",
        "    'quantization_config': QUANTIZATION_CFG,\n",
        "    'lora_config': LORA_CFG,\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "IS_MULTITASK = 'sentiment' in CFG['train_dataset_CFG']['task'].lower() and 'sarcasm' in CFG['train_dataset_CFG']['task'].lower()\n",
        "\n",
        "if IS_MULTITASK:\n",
        "    print(\"Training in multitask mode.\")\n",
        "    if CFG['classification_head'] in ['linear', 'conv', 'lstm']:\n",
        "        print(f\"Using {CFG['classification_head']} classification head (single task head) for multi-task learning. Aborting...\")\n",
        "        exit(1)\n",
        "else:\n",
        "    print(\"Training in single task mode.\")\n",
        "    if CFG['classification_head'] in ['multi_task_conv', 'cross_talk_conv']:\n",
        "        print(f\"Using {CFG['classification_head']} classification head (multi-task head) for single task learning. Aborting...\")\n",
        "        exit(1)\n",
        "\n",
        "print(f\"Training with min_length={CFG['min_length']} and max_length={CFG['max_length']}\")\n",
        "\n",
        "quantization_config = transformers.BitsAndBytesConfig(\n",
        "    **CFG['quantization_config']\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    **CFG['lora_config']\n",
        ")\n",
        "\n",
        "print(\"Quantization and LoRA configurations set.\")\n",
        "\n",
        "# for wandb\n",
        "run_name = f\"{training_dataset_name}_{CFG['classification_head']}_spatten\"\n",
        "print(f\"Run name is: {run_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6hBUztl12yCE",
      "metadata": {
        "id": "6hBUztl12yCE"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(CFG['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e93X5XC82sih",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e93X5XC82sih",
        "outputId": "39d5e782-bc43-4b84-e34a-4ef2a060368f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b1b893",
      "metadata": {
        "id": "58b1b893"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b3fb6e87",
      "metadata": {
        "id": "b3fb6e87"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(os.path.join(CFG['train_dataset_CFG']['root_folder'], CFG['train_dataset_CFG']['file_name'])):\n",
        "    raise Exception('Training file not found! Please check the train_dataset_CFG configuration.')\n",
        "\n",
        "if not os.path.exists(\"./dataset/besstie/train.csv\") or not os.path.exists(\"./dataset/besstie/valid.csv\"):\n",
        "    print(\"Downloading BESSTIE dataset...\")\n",
        "    # Login using e.g. `huggingface-cli login` to access this dataset\n",
        "    df = pd.read_csv(\"hf://datasets/unswnlporg/BESSTIE/train.csv\")\n",
        "    df.to_csv(\"./dataset/besstie/train.csv\", index=False)\n",
        "    df = pd.read_csv(\"hf://datasets/unswnlporg/BESSTIE/valid.csv\")\n",
        "    df.to_csv(\"./dataset/besstie/valid.csv\", index=False)\n",
        "    print(\"BESSTIE dataset downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3cc77b73",
      "metadata": {
        "id": "3cc77b73"
      },
      "outputs": [],
      "source": [
        "def get_dataset(dataset_CFG, minlength, maxlength, tokenizer):\n",
        "    dataset_name = dataset_CFG['dataset_name'].lower()\n",
        "    if dataset_name == 'twitter':\n",
        "        from dataset.twitter.dataset_twitter import TwitterDataSet\n",
        "        dataset = TwitterDataSet(\n",
        "            **dataset_CFG,\n",
        "            tokenizer=tokenizer,\n",
        "            minlength=minlength,\n",
        "            maxlength=maxlength\n",
        "        )\n",
        "    elif dataset_name == 'besstie':\n",
        "        from dataset.besstie.dataset_besstie import BesstieDataSet\n",
        "        dataset = BesstieDataSet(\n",
        "            **dataset_CFG,\n",
        "            tokenizer=tokenizer,\n",
        "            minlength=minlength,\n",
        "            maxlength=maxlength,\n",
        "        )\n",
        "    elif dataset_name == 'bicodemix':\n",
        "        from dataset.bicodemix.dataset_bicodemix import BicodemixDataSet\n",
        "        dataset = BicodemixDataSet(\n",
        "            **dataset_CFG,\n",
        "            tokenizer=tokenizer,\n",
        "            minlength=minlength,\n",
        "            maxlength=maxlength,\n",
        "        )\n",
        "    elif dataset_name == 'yelp':\n",
        "        #TODO: implement Yelp dataset class\n",
        "        raise Exception(\"Yelp dataset not yet implemented.\")\n",
        "    else:\n",
        "        raise Exception(f\"Dataset {dataset_name} not recognized.\")\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85d7a68",
      "metadata": {
        "id": "f85d7a68"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1967f6c",
      "metadata": {
        "id": "f1967f6c"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac415049",
      "metadata": {
        "id": "ac415049"
      },
      "source": [
        "### Back-bone and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1af5c2ab",
      "metadata": {
        "id": "1af5c2ab"
      },
      "outputs": [],
      "source": [
        "def get_tokenizer_and_encoder(model_name:str):\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    model = transformers.AutoModel.from_pretrained(model_name)\n",
        "    return tokenizer, model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a1b74f",
      "metadata": {
        "id": "b9a1b74f"
      },
      "source": [
        "### Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e29dc516",
      "metadata": {
        "id": "e29dc516"
      },
      "outputs": [],
      "source": [
        "class MultiKernelConvs(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        kernel_sizes=(2, 3, 5),\n",
        "        dropout=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList([\n",
        "            torch.nn.Conv1d(\n",
        "                in_channels=input_size,\n",
        "                out_channels=hidden_size//len(kernel_sizes),\n",
        "                kernel_size=k,\n",
        "                padding=k // 2\n",
        "            )\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "\n",
        "        # self.classifier = torch.nn.Linear(\n",
        "        #     hidden_size * len(kernel_sizes),\n",
        "        #     num_labels\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, H, L)\n",
        "        conv_outputs = []\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = self.activation(conv(x))      # (B, C, L)\n",
        "            h = self.pool(h).squeeze(-1)       # (B, C)\n",
        "            conv_outputs.append(h)\n",
        "\n",
        "        x = torch.cat(conv_outputs, dim=1)    # (B, C * num_kernels)\n",
        "        x = self.flatten(self.dropout(x))\n",
        "        # logits = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class ConvClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, num_labels=2, linear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        if linear:\n",
        "            self.conv = torch.nn.Sequential(\n",
        "                MultiKernelConvs(\n",
        "                    input_size=input_size,\n",
        "                    hidden_size=hidden_size,\n",
        "                    kernel_sizes=(3,),\n",
        "                ), # (B, hidden_size)\n",
        "                torch.nn.Linear(hidden_size, num_labels)\n",
        "            )\n",
        "        else:\n",
        "            self.conv = torch.nn.Sequential(\n",
        "                MultiKernelConvs(\n",
        "                    input_size=input_size,\n",
        "                    hidden_size=hidden_size,\n",
        "                    kernel_sizes=(3,),\n",
        "                ) # (B, hidden_size)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class MultiTaskConvHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        num_sentiment_labels: int,\n",
        "        num_sarcasm_labels: int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sentiment_head = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_sentiment_labels\n",
        "        )\n",
        "\n",
        "        self.sarcasm_head = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_sarcasm_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        \"\"\"\n",
        "        sequence_output: last_hidden_state from BERT\n",
        "        shape: (batch, seq_len, hidden_size)\n",
        "        \"\"\"\n",
        "        sentiment_logits = self.sentiment_head(sequence_output)\n",
        "        sarcasm_logits = self.sarcasm_head(sequence_output)\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": sentiment_logits,\n",
        "            \"sarcasm\": sarcasm_logits\n",
        "        }\n",
        "\n",
        "class CrossTalkHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        conv_hidden_size,\n",
        "        num_sentiment_labels,\n",
        "        num_sarcasm_labels,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=conv_hidden_size,\n",
        "            linear = False\n",
        "        )\n",
        "\n",
        "        # task-specific embeddings\n",
        "        self.sentiment_embed = torch.nn.Linear(\n",
        "            conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "        self.sarcasm_embed = torch.nn.Linear(\n",
        "            conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "\n",
        "        # cross-talk layers\n",
        "        self.sentiment_fuse = torch.nn.Linear(\n",
        "            2 * conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "        self.sarcasm_fuse = torch.nn.Linear(\n",
        "            2 * conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "\n",
        "        self.sentiment_out = torch.nn.Linear(\n",
        "            #Â conv_hidden_size, np.max([num_sentiment_labels, num_sarcasm_labels])\n",
        "            conv_hidden_size, num_sentiment_labels\n",
        "        )\n",
        "        self.sarcasm_out = torch.nn.Linear(\n",
        "            conv_hidden_size, num_sarcasm_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        shared = self.encoder(sequence_output)\n",
        "\n",
        "        # first linear layer\n",
        "        sent_feat = self.sentiment_embed(shared)\n",
        "        sarc_feat = self.sarcasm_embed(shared)\n",
        "\n",
        "        # cross-talk\n",
        "        sent_feat_cross = self.sentiment_fuse(\n",
        "            torch.cat([sarc_feat, sent_feat], dim=-1)\n",
        "        )\n",
        "        sarc_feat_cross = self.sarcasm_fuse(\n",
        "            torch.cat([sarc_feat, sent_feat], dim=-1)\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": self.sentiment_out(sent_feat_cross),\n",
        "            \"sarcasm\": self.sarcasm_out(sarc_feat_cross)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d6f5d248",
      "metadata": {
        "id": "d6f5d248"
      },
      "outputs": [],
      "source": [
        "def get_classification_head(method: str, input_size:int, hidden_size: int, num_labels: int):\n",
        "    num_sent_labels, num_sarc_labels = num_labels\n",
        "\n",
        "    # Single task case\n",
        "    if not IS_MULTITASK:\n",
        "        num_task_labels = max(num_sent_labels, num_sarc_labels)\n",
        "\n",
        "    if method == \"linear\":\n",
        "        return torch.nn.Linear(input_size, num_task_labels)\n",
        "    elif method == \"conv\":\n",
        "        return ConvClassificationHead(input_size, hidden_size, num_task_labels)\n",
        "    elif method == \"lstm\":\n",
        "        return torch.nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "    elif method == \"multi_conv\":\n",
        "        return torch.nn.Sequential(\n",
        "            MultiKernelConvs(\n",
        "                input_size=input_size,\n",
        "                hidden_size=hidden_size,\n",
        "                kernel_sizes=(2, 3, 5),\n",
        "                dropout=0.1\n",
        "            ),\n",
        "            torch.nn.Linear(hidden_size, num_task_labels)\n",
        "        )\n",
        "    elif method == 'multi_task_conv':\n",
        "        return MultiTaskConvHead(input_size, hidden_size, num_sent_labels, num_sarc_labels)\n",
        "    elif method == 'cross_talk_conv':\n",
        "        return CrossTalkHead(input_size, hidden_size, num_sent_labels, num_sarc_labels)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown classification head method: {method}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8533b24",
      "metadata": {
        "id": "a8533b24"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e508f6ad",
      "metadata": {
        "id": "e508f6ad"
      },
      "outputs": [],
      "source": [
        "class MyClassifier(torch.nn.Module):\n",
        "    def __init__(self, base_model_name, classification_head_name, num_labels, multitask:bool):\n",
        "        super().__init__()\n",
        "\n",
        "        self.multitask = multitask\n",
        "\n",
        "        num_sent_labels, num_sarc_labels = num_labels\n",
        "\n",
        "        # Single task case\n",
        "        if not self.multitask:\n",
        "            num_task_labels = max(num_sent_labels, num_sarc_labels)\n",
        "\n",
        "        self.tokenizer, self.base_model = get_tokenizer_and_encoder(base_model_name)\n",
        "        self.hidden_size = self.base_model.config.hidden_size\n",
        "        self.dropout = torch.nn.Dropout(self.base_model.config.hidden_dropout_prob)\n",
        "\n",
        "        self.classification_head_name = classification_head_name\n",
        "\n",
        "        self.classification_head = get_classification_head(\n",
        "            classification_head_name, self.hidden_size, self.hidden_size, num_labels\n",
        "        )\n",
        "\n",
        "        if classification_head_name == \"lstm\":\n",
        "            self.output_layer = torch.nn.Linear(self.hidden_size*2, num_task_labels)\n",
        "\n",
        "    def get_tokenizer(self) -> transformers.PreTrainedTokenizer:\n",
        "        return self.tokenizer\n",
        "\n",
        "    def forward(self, inputs, task=None):\n",
        "        outputs = self.base_model(**inputs)\n",
        "        sequence = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        if self.classification_head_name == \"linear\":\n",
        "            cls_rep = sequence[:, 0, :]\n",
        "            logits = self.classification_head(cls_rep)\n",
        "\n",
        "        elif self.classification_head_name == \"conv\":\n",
        "            # x: (batch, seq_len, hidden_size)\n",
        "            x = sequence.transpose(1, 2)  # -> (batch, hidden_size, seq_len)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        elif self.classification_head_name == \"lstm\":\n",
        "            #TODO: check if works correctly\n",
        "            lstm_out, _ = self.classification_head(sequence)\n",
        "            cls_rep = lstm_out[:, 0, :]\n",
        "            logits = self.output_layer(cls_rep)\n",
        "\n",
        "        elif self.classification_head_name == 'multi_conv':\n",
        "            # TODO: implement\n",
        "            logits = None\n",
        "\n",
        "        elif self.classification_head_name == 'multi_task_conv':\n",
        "            x = sequence.transpose(1, 2)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        elif self.classification_head_name == 'cross_talk_conv':\n",
        "            x = sequence.transpose(1, 2)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        if self.multitask and task is not None:\n",
        "            return logits[task]\n",
        "        else:\n",
        "            return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812b59c7",
      "metadata": {
        "id": "812b59c7"
      },
      "source": [
        "### SpAtten"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eca838c",
      "metadata": {
        "id": "9eca838c"
      },
      "source": [
        "#### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bc7f1cdc",
      "metadata": {
        "id": "bc7f1cdc"
      },
      "outputs": [],
      "source": [
        "def topk_masking(scores, keep_ratio):\n",
        "    \"\"\"\n",
        "    Create a hard mask by keeping the top-k tokens based on scores.\n",
        "    Args:\n",
        "        scores (torch.Tensor): Scores for each token (batch_size, seq_len).\n",
        "        keep_ratio (float): Ratio of tokens to keep (between 0 and 1).\n",
        "    Returns:\n",
        "        torch.Tensor: Hard mask (batch_size, seq_len) with 1s for kept tokens and 0s for pruned tokens.\n",
        "    \"\"\"\n",
        "    _, seq_len = scores.size()\n",
        "    k = int(seq_len * keep_ratio)\n",
        "\n",
        "    # Get the top-k indices\n",
        "    topk_indices = torch.topk(scores, k, dim=-1).indices\n",
        "\n",
        "    # Create a mask initialized to zeros\n",
        "    mask = torch.zeros_like(scores)\n",
        "\n",
        "    # Scatter 1s into the mask at the top-k indices\n",
        "    mask.scatter_(1, topk_indices, 1)\n",
        "\n",
        "    return mask\n",
        "\n",
        "def magnitude_head_scores(attention_output, num_heads):\n",
        "    \"\"\"\n",
        "    attention_output: (batch, seq_len, hidden_size)\n",
        "    returns: (batch, num_heads)\n",
        "    \"\"\"\n",
        "    batch_size, seq_len, hidden_size = attention_output.size()\n",
        "    head_dim = hidden_size // num_heads\n",
        "\n",
        "    # E \\in (batch, heads, L0, D)\n",
        "    E = attention_output.view(\n",
        "        batch_size, seq_len, num_heads, head_dim\n",
        "    ).permute(0, 2, 1, 3)\n",
        "\n",
        "    # s_h = sum_{l,d} |E|\n",
        "    head_scores = E.abs().sum(dim=(2, 3))  # (batch, heads)\n",
        "\n",
        "    # print(\"Raw head scores (summed magnitudes):\", head_scores.cpu().detach()/seq_len)\n",
        "    return head_scores/seq_len\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9174658",
      "metadata": {
        "id": "c9174658"
      },
      "source": [
        "#### A layer of bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8e278b42",
      "metadata": {
        "id": "8e278b42"
      },
      "outputs": [],
      "source": [
        "class CascadingMaskBertLayer(BertLayer):\n",
        "    def __init__(self, config: BertConfig, prune_token_percent, prune_head_percent, visualize=False):\n",
        "        super().__init__(config)\n",
        "        self.prune_token_percent = prune_token_percent\n",
        "        self.prune_head_percent = prune_head_percent\n",
        "        self.visualize = visualize\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        token_mask=None,\n",
        "        head_mask=None,\n",
        "        output_attentions=True,\n",
        "        output_hidden_states=False,\n",
        "    ):\n",
        "        if token_mask is None:\n",
        "            token_mask = torch.ones(\n",
        "                hidden_states.size()[:-1],\n",
        "                device=hidden_states.device\n",
        "            )\n",
        "\n",
        "        batch_size = hidden_states.size(0)\n",
        "        num_heads = self.attention.self.num_attention_heads\n",
        "\n",
        "        if head_mask is None:\n",
        "            head_mask = torch.ones(\n",
        "                (batch_size, num_heads),\n",
        "                device=hidden_states.device\n",
        "            )\n",
        "\n",
        "        head_mask_expanded = head_mask[:, :, None, None]\n",
        "\n",
        "        # ---- Apply previous cascade ----\n",
        "        hidden_states = hidden_states * token_mask.unsqueeze(-1)\n",
        "\n",
        "        # ---- Extend attention mask ----\n",
        "        cascade_attn_mask = (1.0 - token_mask) * -1e4\n",
        "        attention_mask = attention_mask + cascade_attn_mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # ---- Self-attention ----\n",
        "        self_attention_outputs = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask=head_mask_expanded,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        attention_output, attention_scores = self_attention_outputs\n",
        "\n",
        "        if self.visualize:\n",
        "            for sample in range(attention_scores.size(0)):\n",
        "                if head_mask_expanded[sample,0,0,0] == 0:  # Check if head 0 is active for this sample\n",
        "                    print(f\"Sample {sample} head 0 is pruned, skipping attention score visualization.\")\n",
        "                    continue\n",
        "                plt.figure()\n",
        "                plt.title(f\"Attention scores for sample {sample} (head 0):\")\n",
        "                sns.heatmap(attention_scores[sample,0,:,:].cpu().detach(), cmap='viridis')\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "            plt.figure()\n",
        "            plt.title(f\"Head mask for each sample\")\n",
        "            # sns.heatmap(attention_scores.sum(dim=(2,3)).cpu().detach(), cmap='viridis')\n",
        "            sns.heatmap(head_mask, cmap='viridis')\n",
        "            plt.ylabel(\"Sample index\")\n",
        "            plt.xlabel(\"Head index\")\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        # ---- Compute new token decisions ----\n",
        "        token_scores = attention_scores.sum(dim=(1,2))  # (batch_size, seq_len)\n",
        "\n",
        "        new_token_mask = topk_masking(\n",
        "            token_scores,\n",
        "            keep_ratio=1-self.prune_token_percent  # eliminate bottom pt% tokens\n",
        "        )\n",
        "        # Protect CLS\n",
        "        new_token_mask[:, 0] = 1.0\n",
        "\n",
        "        # ---- CASCADE ----\n",
        "        token_mask = token_mask * new_token_mask\n",
        "\n",
        "\n",
        "\n",
        "        # ---- Compute new head decisions ----\n",
        "        heads_scores = magnitude_head_scores(attention_output, num_heads=num_heads)\n",
        "\n",
        "        new_head_mask = topk_masking(\n",
        "            heads_scores,  # (batch_size, num_heads)\n",
        "            keep_ratio=1-self.prune_head_percent\n",
        "        )\n",
        "\n",
        "        # ---- CASCADE ----\n",
        "        head_mask = head_mask * new_head_mask\n",
        "\n",
        "\n",
        "\n",
        "        # ---- Feed-forward ----\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "\n",
        "        return layer_output, token_mask, head_mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b79261d",
      "metadata": {
        "id": "7b79261d"
      },
      "source": [
        "#### Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "84e1dcb3",
      "metadata": {
        "id": "84e1dcb3"
      },
      "outputs": [],
      "source": [
        "class CascadingBertEncoder(BertEncoder):\n",
        "    def __init__(self, config, visualize, visualize_prune_decisions=False):\n",
        "        super().__init__(config)\n",
        "        self.layer = torch.nn.ModuleList([\n",
        "            CascadingMaskBertLayer(config, config.pt[i], config.ph[i], visualize=visualize[i])\n",
        "            for i in range(config.num_hidden_layers)\n",
        "        ])\n",
        "        self.visualize_prune_decisions = visualize_prune_decisions\n",
        "\n",
        "        # for i in range(len(self.bert.encoder.layer)):\n",
        "        #     self.bert.encoder.layer[i] = CascadingMaskBertLayer(self.bert.config, pt_schedule[i], ph_schedule[i])\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        output_attentions=False,\n",
        "        output_hidden_states=False,\n",
        "        return_dict=True,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        batch_size = hidden_states.size(0)\n",
        "        token_mask = None\n",
        "        head_mask = None\n",
        "\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            hidden_states, token_mask, head_mask = layer_module(\n",
        "                hidden_states,\n",
        "                attention_mask=attention_mask,\n",
        "                token_mask=token_mask,\n",
        "                head_mask=head_mask,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "            )\n",
        "\n",
        "            if self.visualize_prune_decisions:\n",
        "                print(f\"Layer {i} active tokens:\", token_mask.sum(dim=1))\n",
        "                print(f\"Layer {i} active heads:\", head_mask.sum(dim=1))\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [\n",
        "                    hidden_states,\n",
        "                    None,\n",
        "                    None,\n",
        "                    None,\n",
        "                    None,\n",
        "                ]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=None,\n",
        "            hidden_states=None,\n",
        "            attentions=None,\n",
        "            cross_attentions=None,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26e9b2e2",
      "metadata": {
        "id": "26e9b2e2"
      },
      "source": [
        "#### Top level model\n",
        "The only difference from previously defined classifier 'MyClassifier' is the overwrtite of 'self.bert.encoder' with a custom class to add the functionalities required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7469d01f",
      "metadata": {
        "id": "7469d01f"
      },
      "outputs": [],
      "source": [
        "class MyClassifierSpAtten(torch.nn.Module):\n",
        "    def __init__(self, config:BertConfig, base_model_name=\"bert-base-uncased\", num_labels=2):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(base_model_name, config=config)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(base_model_name)\n",
        "\n",
        "        self.bert.encoder = CascadingBertEncoder(self.bert.config, visualize=[False for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "        num = num_labels if isinstance(num_labels, int) else num_labels[0]+num_labels[1]\n",
        "        self.dense = torch.nn.Linear(config.hidden_size, num)\n",
        "\n",
        "    def forward(self, inputs, task:str=None):\n",
        "        bert_outputs = self.bert(**inputs)\n",
        "\n",
        "        # print(\"BERT output:\", bert_outputs)\n",
        "        cls_token = bert_outputs.last_hidden_state[:, 0]  # Use [CLS] token representation\n",
        "        return self.dense(cls_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fe1df2cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "95e7a4976d3444dcbefe3235b03303c1",
            "5e937b7caf4b44ca9a215360a44f376d",
            "5b0ebbb1beb745ee92fd32aee4f7ac50",
            "b3e223141f194e55b0325f5779c04a73",
            "24e419167ce1467d9e52ff41567ab561",
            "8608724097e8437f86abefd85f7a6424",
            "dc374e1e36c54f5f8502e98d623e33d1",
            "6485a9d1ff9b4ce289de6a0731e57e76",
            "0e603f4b962444caab0f986e31c73499",
            "c10a716e7ea1412ba3c23d7e91cf696c",
            "d201bc9bb8144d55a37d9a77ae6781ba",
            "a74d19373fcb45d593da89043bca4de1",
            "1c7858c358f446e18795734baacd0348",
            "0a01a30e6a074d1b9c1f7c98007fd677",
            "7b55e0f4ac8043deb25949d06632a758",
            "f7c65a0c26b349739f1778418e08aab6",
            "fca71463295445baabb1bac2ca3856b8",
            "295543a3a8f14ee19dce613edf8d7bf6",
            "a207cae11dce41338817cab287f68ca1",
            "52b57208d502401f81cd936f59df5ea3",
            "6d866d4d638b43078fcf85810f4a532e",
            "3f1abe478cb04047bd841309148a7af7",
            "1b33e59830f24c039caeca53a4a5e30b",
            "c1762b91a0e44647ac5557345d33ae3d",
            "33bbcacfca3b48cea423a9b3b36f0a87",
            "01093c571a3c47179571324c9cead1a8",
            "d207c873288f47d9b101b0493e13ffb9",
            "e8dbbe229d4349709c566432e777b8b4",
            "c12b076f6dff4111a993ece3b3670b34",
            "7c7beae075874f9792d05341e990a314",
            "cca61f2123954aed9669d2982211bf89",
            "654d918c7dac4abda2e08e6b1cb31857",
            "e86ca2284ca7445db6c09add213c24ee",
            "c24f00f44f7e4c61b1e5dcaa9b47ca25",
            "0db95f2e62494591864545e0307d871b",
            "cbb424a3057a40a898adb4d8d954fd00",
            "1d4c4b8bc74344edb9378daff87def4f",
            "6f6cbf7ad3a24f07a340e05df91dbcc5",
            "d649c5756c4941ee99412f286ab7683a",
            "1cadec38201048d692f53ba92720fc19",
            "59254eefe7464914954c72ce057a62a4",
            "417d71c4f3ef4aa88df0fd46ea82699f",
            "22bb7fdc4a814ba592ef57101000caa3",
            "02d7ca3e1394469d97b86ad5782f489e",
            "57ac0053e79c443e8870242bb9551ad0",
            "46eda1d5071b463fa35bc213d57c53ca",
            "f96c54650b77427fb94237f8da840b49",
            "8a85fa67c4be47db88be5cbc95611b14",
            "ea160e53fc1e4a8fb5b85e5353b92cf2",
            "2a8f02567d7c4d2da994347dec46a5c6",
            "55c07f47720749cd95273df5b9cf7bb5",
            "09dab05e0fb44fb2abba4a67bddf3288",
            "34858c3a39c94db9ae0e805f7c94d6e7",
            "5ce663cb119a4416946f8363dcd9a911",
            "a532440b02a54510867d27c995c31dfa",
            "da70aa0684fe4bf8ba79bf226cb861f8",
            "897473177c71477cb6e57de19ae0bbed",
            "49d0f3ae78ef429285f527a57e8cda08",
            "7f4e264b906a44878a8ef9877d7fda77",
            "73f09aa3a7d74c24aff26e5c8684b330",
            "74b9950c17ba4b8fb470297b42ebc35e",
            "9fb892b8da6e4c77828169594890fb2b",
            "2ee2e851b4f144638f27d00a7c697204",
            "f0d14782c16d4e3e919263dc3f867fb3",
            "73ff411b9ca94f638fb03c5566746de4",
            "1974f867cab04d609e72bd793026184e"
          ]
        },
        "id": "fe1df2cc",
        "outputId": "f1de8967-212f-4641-8298-dd440a6611b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95e7a4976d3444dcbefe3235b03303c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cascading token pruning schedule: [0.0, 0.09999999999999998, 0.09999999999999998, 0.18999999999999995, 0.18999999999999995, 0.2709999999999999, 0.2709999999999999, 0.3438999999999999, 0.3438999999999999, 0.4095099999999998, 0.4095099999999998, 0.46855899999999984]\n",
            "Cascading head pruning schedule: [0.0, 0.09999999999999998, 0.09999999999999998, 0.18999999999999995, 0.18999999999999995, 0.2709999999999999, 0.2709999999999999, 0.3438999999999999, 0.3438999999999999, 0.4095099999999998, 0.4095099999999998, 0.46855899999999984]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a74d19373fcb45d593da89043bca4de1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b33e59830f24c039caeca53a4a5e30b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertModel LOAD REPORT from: bert-base-uncased\n",
            "Key                                        | Status     |  | \n",
            "-------------------------------------------+------------+--+-\n",
            "cls.seq_relationship.weight                | UNEXPECTED |  | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED |  | \n",
            "cls.predictions.bias                       | UNEXPECTED |  | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED |  | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED |  | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED |  | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c24f00f44f7e4c61b1e5dcaa9b47ca25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57ac0053e79c443e8870242bb9551ad0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da70aa0684fe4bf8ba79bf226cb861f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "MyClassifierSpAtten(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CascadingBertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x CascadingMaskBertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dense): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_cfg = BertConfig.from_pretrained(CFG['model_name'])\n",
        "\n",
        "bert_cfg.output_attentions = True\n",
        "bert_cfg.output_hidden_states = False\n",
        "bert_cfg.return_dict = True\n",
        "\n",
        "pt_schedule = [0.1 for _ in range(bert_cfg.num_hidden_layers)]\n",
        "for i in range(len(pt_schedule)):\n",
        "    if i % 2 == 0:\n",
        "        pt_schedule[i] = 0.0\n",
        "pt_schedule[0] = 0.0  # No pruning in the first layer\n",
        "\n",
        "ph_schedule = [0.1 for _ in range(bert_cfg.num_hidden_layers)]\n",
        "for i in range(len(ph_schedule)):\n",
        "    if i % 2 == 0:\n",
        "        ph_schedule[i] = 0.0\n",
        "ph_schedule[0] = 0.0  # No pruning in the first layer\n",
        "\n",
        "def calculate_p_schedule(p_schedule):\n",
        "    for i in range(len(p_schedule)):\n",
        "        if i == 0:\n",
        "            p_schedule[i] = 0.0\n",
        "        else:\n",
        "            p_schedule[i] = 1-(1-p_schedule[i-1])*(1-p_schedule[i])\n",
        "\n",
        "    return p_schedule\n",
        "\n",
        "\n",
        "bert_cfg.pt = calculate_p_schedule(pt_schedule)\n",
        "print(\"Cascading token pruning schedule:\", bert_cfg.pt)\n",
        "\n",
        "bert_cfg.ph = calculate_p_schedule(ph_schedule)\n",
        "print(\"Cascading head pruning schedule:\", bert_cfg.ph)\n",
        "\n",
        "\n",
        "MyClassifierSpAtten(\n",
        "    config=bert_cfg,\n",
        "    base_model_name=CFG['model_name'],\n",
        "    num_labels=len(\n",
        "        CFG['train_dataset_CFG']['classes'][CFG['train_dataset_CFG']['task']]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "745d9d86",
      "metadata": {
        "id": "745d9d86"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f36b0dc",
      "metadata": {
        "id": "5f36b0dc"
      },
      "outputs": [],
      "source": [
        "class MyDecoder(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder model with LoRA and quantization for sentiment and/or sarcasm analysis.\n",
        "    \"\"\"\n",
        "    def __init__(self, decoder_name, quantization_config, lora_config, task, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.quantization_config = quantization_config\n",
        "        self.lora_config = lora_config\n",
        "        self.task = task\n",
        "        self.is_multitask = 'sentiment' in self.task.lower() and 'sarcasm' in self.task.lower()\n",
        "        self.device = device\n",
        "\n",
        "        self.decoder = transformers.AutoModelForCausalLM.from_pretrained(decoder_name, quantization_config=self.quantization_config, device_map=self.device)\n",
        "        self.decoder = get_peft_model(self.decoder, self.lora_config)\n",
        "\n",
        "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(decoder_name)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        if self.is_multitask:\n",
        "            #TODO: implement multitask prefill\n",
        "            self.prefill = \"\"\n",
        "        elif self.task.lower() == 'sentiment':\n",
        "            self.prefill = \"\"\"\n",
        "Generate the sentiment of the given text.\n",
        "1 for positive sentiment, and 0 for negative sentiment.\n",
        "Do not give an explanation, just the number.\n",
        "\"\"\"\n",
        "        elif self.task.lower() == 'sarcasm':\n",
        "            self.prefill = \"\"\"\n",
        "Predict if the given text is sarcastic.\n",
        "1 if the text is sarcastic, and 0 if the text is not sarcastic.\n",
        "Do not give an explanation, just the number.\"\"\"\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown task: {self.task}\")\n",
        "\n",
        "    def label_to_str(self, label: torch.Tensor) -> str:\n",
        "        \"\"\"\n",
        "        Applying direcly str(label) adds extra characters (like tensor(...)) that\n",
        "        can confuse the decoder during training.\n",
        "        \"\"\"\n",
        "        if not self.is_multitask:\n",
        "            return str(label.item())\n",
        "        else:\n",
        "            return f\"{label[0].item()},{label[1].item()}\"\n",
        "\n",
        "    def create_train_prompt(self, input):\n",
        "        return [{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"{self.prefill}\\n{input['text']}\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": f\"{self.label_to_str(input['label'])}\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    def create_infer_prompt(self, input):\n",
        "        return [{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"{self.prefill}\\n{input['text']}\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    # TODO: main problem is that loss is computed over all tokens, need to mask\n",
        "    # so that only generated tokens of the task are considered in the loss calculation\n",
        "    # @ChatGPT suggested assistant_token_id = self.tokenizer.convert_tokens_to_ids(self.tokenizer.special_tokens_map[\"bos_token\"])\n",
        "    # or simply to mask everything except last N tokens\n",
        "    # TODO: how to handle batch size > 1? Or do we even need to do this?\n",
        "    # NOTE: assume batch size of 1\n",
        "    def forward(self, input):\n",
        "        # message = self.create_train_prompt(input)\n",
        "        message = [self.create_train_prompt(sample) for sample in input]\n",
        "\n",
        "        # Add special tokens and tokenize\n",
        "        input = self.tokenizer.apply_chat_template(\n",
        "            message,\n",
        "            return_tensors=\"pt\",\n",
        "            add_generation_prompt=False\n",
        "        ).to(self.device)\n",
        "\n",
        "        input_ids = input[\"input_ids\"]      #Â (B, T)\n",
        "        attention_mask = input[\"attention_mask\"]        #Â (B, T)\n",
        "\n",
        "        #TODO: check if label is correctly set\n",
        "        labels = torch.full_like(input_ids, fill_value=-100)        # (B, T)\n",
        "        for i in range(input_ids.size(0)):\n",
        "            last_token_idx = attention_mask[i].sum() - 1\n",
        "            labels[i, last_token_idx] = input_ids[i, last_token_idx]\n",
        "\n",
        "        outputs = self.decoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def infer(self, input):\n",
        "        messages = self.create_infer_prompt(input)\n",
        "\n",
        "        input = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            return_tensors=\"pt\",\n",
        "            add_generation_prompt=True\n",
        "        ).to(self.device)\n",
        "\n",
        "        output_ids = self.decoder.generate(\n",
        "            input_ids=input['input_ids'],\n",
        "            attention_mask=input['attention_mask'],\n",
        "            max_new_tokens=3 if self.is_multitask else 1, #TODO: check if enough/correct\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "        # TODO: check if extracted last token generated\n",
        "        prediction = self.tokenizer.decode(\n",
        "            output_ids[0][input[\"input_ids\"].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        ).strip()\n",
        "\n",
        "        return prediction\n",
        "\n",
        "    def get_tokenizer(self) -> transformers.PreTrainedTokenizer:\n",
        "        return self.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ad8f5e",
      "metadata": {
        "id": "32ad8f5e"
      },
      "outputs": [],
      "source": [
        "decoder_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "# decoder = MyDecoder(\n",
        "#     decoder_name=decoder_name,\n",
        "#     quantization_config=quantization_config,\n",
        "#     lora_config=lora_config,\n",
        "#     task=CFG['train_dataset_CFG']['task'],\n",
        "#     device=device\n",
        "# )\n",
        "\n",
        "# tokenizer = decoder.get_tokenizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1ee6de",
      "metadata": {
        "id": "3e1ee6de"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5cf3a73",
      "metadata": {
        "id": "a5cf3a73"
      },
      "source": [
        "## Multitask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c9dd2bae",
      "metadata": {
        "id": "c9dd2bae"
      },
      "outputs": [],
      "source": [
        "def train_SS(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "\n",
        "    train_sarc_loss = 0.0\n",
        "    train_sent_loss = 0.0\n",
        "    train_sarc_acc = 0.0\n",
        "    train_sent_acc = 0.0\n",
        "    c1, c2 = criterion\n",
        "\n",
        "    pbar = tqdm.tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "\n",
        "        local_labels = batch['label'].to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        sent_loss = c1(outputs['sentiment'], local_labels[:,0])\n",
        "        sarc_loss = c2(outputs['sarcasm'], local_labels[:,1])\n",
        "\n",
        "        loss = sarc_loss + sent_loss\n",
        "        loss.backward()\n",
        "        # optimizer.pc_backward([sarc_loss, sent_loss])\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_sarc_loss += sarc_loss.item()\n",
        "        train_sent_loss += sent_loss.item()\n",
        "\n",
        "        _, preds_sarc = torch.max(outputs['sarcasm'], dim=1)\n",
        "        _, preds_sent = torch.max(outputs['sentiment'], dim=1)\n",
        "        train_sarc_acc += torch.sum(preds_sarc == local_labels[:,1]).item()\n",
        "        train_sent_acc += torch.sum(preds_sent == local_labels[:,0]).item()\n",
        "\n",
        "    return train_sarc_loss / len(train_loader), train_sent_loss / len(train_loader), train_sarc_acc / (len(train_loader.dataset)), train_sent_acc / (len(train_loader.dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "rJ5yvxgVrJpV",
      "metadata": {
        "id": "rJ5yvxgVrJpV"
      },
      "outputs": [],
      "source": [
        "def train_spAtten(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "\n",
        "    train_sarc_loss = 0.0\n",
        "    train_sent_loss = 0.0\n",
        "    train_sarc_acc = 0.0\n",
        "    train_sent_acc = 0.0\n",
        "    c1, c2 = criterion\n",
        "\n",
        "    pbar = tqdm.tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "\n",
        "        local_labels = batch['label'].to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        sent_loss = c1(outputs[:,:3], local_labels[:,0])\n",
        "        sarc_loss = c2(outputs[:,3:], local_labels[:,1])\n",
        "\n",
        "        loss = sarc_loss + sent_loss\n",
        "        loss.backward()\n",
        "        # optimizer.pc_backward([sarc_loss, sent_loss])\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_sarc_loss += sarc_loss.item()\n",
        "        train_sent_loss += sent_loss.item()\n",
        "\n",
        "        _, preds_sarc = torch.max(outputs[:,:3], dim=1)\n",
        "        _, preds_sent = torch.max(outputs[:,3:], dim=1)\n",
        "        train_sarc_acc += torch.sum(preds_sarc == local_labels[:,1]).item()\n",
        "        train_sent_acc += torch.sum(preds_sent == local_labels[:,0]).item()\n",
        "\n",
        "    return train_sarc_loss / len(train_loader), train_sent_loss / len(train_loader), train_sarc_acc / (len(train_loader.dataset)), train_sent_acc / (len(train_loader.dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a43ec493",
      "metadata": {
        "id": "a43ec493"
      },
      "source": [
        "## Singletask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8c33ce5c",
      "metadata": {
        "id": "8c33ce5c"
      },
      "outputs": [],
      "source": [
        "def train(model, task, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    pbar = tqdm.tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "\n",
        "        local_labels = batch['label'].flatten().to(device)\n",
        "        outputs = model(inputs, task=task)\n",
        "\n",
        "        loss = criterion(outputs, local_labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        train_acc += torch.sum(preds == local_labels).item()\n",
        "\n",
        "    return train_loss / len(train_loader), train_acc / (len(train_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "11990d23",
      "metadata": {
        "id": "11990d23"
      },
      "outputs": [],
      "source": [
        "def train_decoder(model, task, train_loader, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    pbar = tqdm.tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "\n",
        "        local_labels = batch['label'].flatten().to(device)\n",
        "        outputs = model(inputs, task=task)\n",
        "\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # TODO: check accuracy calculation for decoder\n",
        "        # other solution by ChatGPT\n",
        "        # preds = model.infer(batch)  # \"0\" o \"1\"\n",
        "        # train_acc += int(preds == local_labels)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        train_acc += torch.sum(preds == local_labels).item()\n",
        "\n",
        "    return train_loss / len(train_loader), train_acc / (len(train_loader.dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e369c4f",
      "metadata": {
        "id": "3e369c4f"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5440b731",
      "metadata": {
        "id": "5440b731"
      },
      "source": [
        "## Multitask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7bd4e582",
      "metadata": {
        "id": "7bd4e582"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def validate_SS(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_sarc_acc = 0.0\n",
        "    val_sent_acc = 0.0\n",
        "    val_sarc_loss = 0.0\n",
        "    val_sent_loss = 0.\n",
        "    all_sent_preds = []\n",
        "    all_sent_labels = []\n",
        "    all_sarc_preds = []\n",
        "    all_sarc_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = {\n",
        "                'input_ids': batch['input_ids'].to(device),\n",
        "                'attention_mask': batch['attention_mask'].to(device)\n",
        "            }\n",
        "            local_labels = batch['label'].to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            sentiment_criterion, sarcasm_criterion = criterion\n",
        "            sarc_loss = sarcasm_criterion(outputs['sarcasm'], local_labels[:,1])\n",
        "            sent_loss = sentiment_criterion(outputs['sentiment'], local_labels[:,0])\n",
        "\n",
        "            _, preds_sarc = torch.max(outputs['sarcasm'], dim=1)\n",
        "            _, preds_sent = torch.max(outputs['sentiment'], dim=1)\n",
        "\n",
        "            val_sent_acc += torch.sum(preds_sent == local_labels[:,0]).item()\n",
        "            val_sarc_acc += torch.sum(preds_sarc == local_labels[:,1]).item()\n",
        "\n",
        "            val_sarc_loss += sarc_loss.item()\n",
        "            val_sent_loss += sent_loss.item()\n",
        "\n",
        "            all_sent_preds.extend(preds_sent.cpu().numpy())\n",
        "            all_sent_labels.extend(local_labels[:,0].cpu().numpy())\n",
        "            all_sarc_preds.extend(preds_sarc.cpu().numpy())\n",
        "            all_sarc_labels.extend(local_labels[:,1].cpu().numpy())\n",
        "\n",
        "\n",
        "    f1_sent = f1_score(all_sent_labels, all_sent_preds, average='weighted')\n",
        "    f1_sarc = f1_score(all_sarc_labels, all_sarc_preds, average='weighted')\n",
        "    return val_sarc_loss / len(val_loader), val_sarc_acc / len(val_loader.dataset), val_sent_loss / len(val_loader), val_sent_acc / len(val_loader.dataset), f1_sarc, f1_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "f57qMteLr_0Z",
      "metadata": {
        "id": "f57qMteLr_0Z"
      },
      "outputs": [],
      "source": [
        "def validate_spAtten(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_sarc_acc = 0.0\n",
        "    val_sent_acc = 0.0\n",
        "    val_sarc_loss = 0.0\n",
        "    val_sent_loss = 0.\n",
        "    all_sent_preds = []\n",
        "    all_sent_labels = []\n",
        "    all_sarc_preds = []\n",
        "    all_sarc_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = {\n",
        "                'input_ids': batch['input_ids'].to(device),\n",
        "                'attention_mask': batch['attention_mask'].to(device)\n",
        "            }\n",
        "            local_labels = batch['label'].to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            sentiment_criterion, sarcasm_criterion = criterion\n",
        "            sarc_loss = sarcasm_criterion(outputs[:,3:], local_labels[:,1])\n",
        "            sent_loss = sentiment_criterion(outputs[:,:3], local_labels[:,0])\n",
        "\n",
        "            _, preds_sarc = torch.max(outputs[:,3:], dim=1)\n",
        "            _, preds_sent = torch.max(outputs[:,:3], dim=1)\n",
        "\n",
        "            val_sent_acc += torch.sum(preds_sent == local_labels[:,0]).item()\n",
        "            val_sarc_acc += torch.sum(preds_sarc == local_labels[:,1]).item()\n",
        "\n",
        "            val_sarc_loss += sarc_loss.item()\n",
        "            val_sent_loss += sent_loss.item()\n",
        "\n",
        "            all_sent_preds.extend(preds_sent.cpu().numpy())\n",
        "            all_sent_labels.extend(local_labels[:,0].cpu().numpy())\n",
        "            all_sarc_preds.extend(preds_sarc.cpu().numpy())\n",
        "            all_sarc_labels.extend(local_labels[:,1].cpu().numpy())\n",
        "\n",
        "\n",
        "    f1_sent = f1_score(all_sent_labels, all_sent_preds, average='weighted')\n",
        "    f1_sarc = f1_score(all_sarc_labels, all_sarc_preds, average='weighted')\n",
        "    return val_sarc_loss / len(val_loader), val_sarc_acc / len(val_loader.dataset), val_sent_loss / len(val_loader), val_sent_acc / len(val_loader.dataset), f1_sarc, f1_sent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f791604e",
      "metadata": {
        "id": "f791604e"
      },
      "source": [
        "## Singletask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c2faa862",
      "metadata": {
        "id": "c2faa862"
      },
      "outputs": [],
      "source": [
        "def validate(model, task, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = {\n",
        "                'input_ids': batch['input_ids'].to(device),\n",
        "                'attention_mask': batch['attention_mask'].to(device)\n",
        "            }\n",
        "            local_labels = batch['label'].flatten().to(device)\n",
        "            outputs = model(inputs, task=task)\n",
        "\n",
        "            loss = criterion(outputs, local_labels)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            val_acc += torch.sum(preds == local_labels).item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(local_labels.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    return val_loss / len(val_loader), val_acc / len(val_loader.dataset), f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf10d73",
      "metadata": {
        "id": "caf10d73"
      },
      "source": [
        "# Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "47a57619",
      "metadata": {
        "id": "47a57619"
      },
      "outputs": [],
      "source": [
        "if CFG['train_dataset_CFG'].get('variety', None) == None:\n",
        "    run_id = f\"{CFG['model_name']}_{CFG['classification_head']}_{CFG['train_dataset_CFG']['dataset_name']}_{CFG['train_dataset_CFG']['task']}_spatten\"\n",
        "else:\n",
        "    run_id = f\"{CFG['model_name']}_{CFG['classification_head']}_{CFG['train_dataset_CFG']['dataset_name']}_{CFG['train_dataset_CFG']['variety']}_{CFG['train_dataset_CFG']['task']}\"\n",
        "if ENABLE_WANDB:\n",
        "    import wandb\n",
        "    #Â NOTE: set run_name\n",
        "    # run_id = None\n",
        "\n",
        "    run = wandb.init(\n",
        "        entity=\"elena-nespolo02-politecnico-di-torino\",\n",
        "        project=\"Figurative Analysis\",\n",
        "        name=run_name,\n",
        "        id=run_id,\n",
        "        resume=\"allow\",\n",
        "        config=CFG,\n",
        "        tags=[CFG['train_dataset_CFG']['dataset_name'], CFG['train_dataset_CFG']['task'], CFG['model_name']]\n",
        "    )\n",
        "\n",
        "    wandb.define_metric(\"epoch/step\")\n",
        "    wandb.define_metric(\"epoch/*\", step_metric=\"epoch/step\")\n",
        "\n",
        "    wandb.define_metric(\"train/step\")\n",
        "    wandb.define_metric(\"train/*\", step_metric=\"train/step\")\n",
        "\n",
        "    wandb.define_metric(\"validate/step\")\n",
        "    wandb.define_metric(\"validate/*\", step_metric=\"validate/step\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7208179d",
      "metadata": {
        "id": "7208179d"
      },
      "source": [
        "# ML pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a7b59a",
      "metadata": {
        "id": "c9a7b59a"
      },
      "outputs": [],
      "source": [
        "models_root_dir = \"./models\"\n",
        "os.makedirs(models_root_dir, exist_ok=True)\n",
        "\n",
        "model_name = CFG['model_name']\n",
        "tokenizer, model = get_tokenizer_and_encoder(model_name)\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# setup classifier model\n",
        "if use_spAtten:\n",
        "    model = MyClassifierSpAtten(\n",
        "        config=bert_cfg,\n",
        "        base_model_name=CFG['model_name'],\n",
        "        num_labels=[len(v) if k in CFG['train_dataset_CFG']['task'].lower() else 0 for k,v in CFG['train_dataset_CFG']['classes'].items()],\n",
        "    ).to(device)\n",
        "else:\n",
        "    model = MyClassifier(\n",
        "        base_model_name=model_name,\n",
        "        classification_head_name=CFG['classification_head'],\n",
        "        num_labels=[len(v) if k in CFG['train_dataset_CFG']['task'].lower() else 0 for k,v in CFG['train_dataset_CFG']['classes'].items()],\n",
        "        multitask=IS_MULTITASK\n",
        "    ).to(device)\n",
        "\n",
        "print(model)\n",
        "train_ds = get_dataset(\n",
        "    CFG['train_dataset_CFG'],\n",
        "    minlength=CFG['min_length'],\n",
        "    maxlength=CFG['max_length'],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "val_ds = get_dataset(\n",
        "    CFG['valid_dataset_CFG'],\n",
        "    minlength=CFG['min_length'],\n",
        "    maxlength=CFG['max_length'],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"Training dataset size:\", len(train_ds))\n",
        "print(\"Validation dataset size:\", len(val_ds))\n",
        "\n",
        "labels_count = {}\n",
        "for t, cs in train_ds.get_label_count().items():\n",
        "    if t in CFG['train_dataset_CFG']['task'].lower():\n",
        "        labels_count[t] = [c for c in cs.values()]\n",
        "print(labels_count)\n",
        "\n",
        "if IS_MULTITASK:\n",
        "    optimizer = PCGrad(torch.optim.Adam(model.parameters(), lr=CFG['lr']))\n",
        "    sarc_weights = labels_count['sarcasm']\n",
        "    sent_weights = labels_count['sentiment']\n",
        "    sum_sarc = sum(sarc_weights)\n",
        "    sum_sent = sum(sent_weights)\n",
        "    sarcasm_criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor([sw/sum_sarc for sw in sarc_weights], dtype=torch.float).to(device)\n",
        "    )\n",
        "    sentiment_criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor([sw/sum_sent for sw in sent_weights], dtype=torch.float).to(device)\n",
        "    )\n",
        "    criterion = [sentiment_criterion, sarcasm_criterion] # a list of per-task losses\n",
        "    print([\n",
        "        x.weight for x in criterion\n",
        "    ])\n",
        "else:\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
        "    weights = labels_count[list(labels_count.keys())[0]]\n",
        "    criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor([w/sum(weights) for w in weights], dtype=torch.float).to(device)\n",
        "    )\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Loading form a starting point\n",
        "if CFG['start_epoch'] > 0 and ENABLE_WANDB:\n",
        "    artifact = run.use_artifact(f'elena-nespolo02-politecnico-di-torino/Figurative Analysis/{run_id}:epoch_{CFG['start_epoch']}', type='model')\n",
        "    artifact_dir = artifact.download()\n",
        "\n",
        "    artifact_path = os.path.join(artifact_dir, run_id+f\"_epoch_{CFG['start_epoch']}.pth\")\n",
        "\n",
        "    checkpoint = torch.load(artifact_path, map_location=device)\n",
        "\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    if not IS_MULTITASK:\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    else:\n",
        "        optimizer.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19fd0067",
      "metadata": {
        "id": "19fd0067"
      },
      "source": [
        "## Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7fa1685",
      "metadata": {
        "id": "b7fa1685"
      },
      "outputs": [],
      "source": [
        "for epoch in range(CFG['start_epoch']+1,CFG['epochs']+1):\n",
        "    print(f\"Epoch {epoch}/{CFG['epochs']}\")\n",
        "\n",
        "    if IS_MULTITASK:\n",
        "        if use_spAtten:\n",
        "            epoch_sarc_loss, epoch_sent_loss, epoch_sarc_acc, epoch_sent_acc = train_spAtten(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "            val_sarc_loss, val_sarc_acc, val_sent_loss, val_sent_acc, f1_sarc, f1_sent = validate_spAtten(model, val_loader, criterion, device)\n",
        "        else:\n",
        "            epoch_sarc_loss, epoch_sent_loss, epoch_sarc_acc, epoch_sent_acc = train_SS(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "            val_sarc_loss, val_sarc_acc, val_sent_loss, val_sent_acc, f1_sarc, f1_sent = validate_SS(model, val_loader, criterion, device)\n",
        "\n",
        "        if ENABLE_WANDB:\n",
        "            run.log({\n",
        "                    \"epoch/step\": epoch,\n",
        "                    \"epoch/train_sarc_loss\": epoch_sarc_loss,\n",
        "                    \"epoch/train_sent_loss\": epoch_sent_loss,\n",
        "                    \"epoch/train_sarc_acc\": epoch_sarc_acc,\n",
        "                    \"epoch/train_sent_acc\": epoch_sent_acc,\n",
        "                    \"epoch/val_sarc_loss\": val_sarc_loss,\n",
        "                    \"epoch/val_sent_loss\": val_sent_loss,\n",
        "                    \"epoch/val_sarc_acc\": val_sarc_acc,\n",
        "                    \"epoch/val_sent_acc\": val_sent_acc\n",
        "                },\n",
        "                commit=True,\n",
        "            )\n",
        "        print(f\"Training Sarcasm Loss: {epoch_sarc_loss:.4f}\")\n",
        "        print(f\"Training Sentiment Loss: {epoch_sent_loss:.4f}\")\n",
        "        print(f\"Training Sarcasm Acc: {epoch_sarc_acc:.4f}\")\n",
        "        print(f\"Training Sentiment Acc: {epoch_sent_acc:.4f}\")\n",
        "        print(f\"Validation Sarcasm Loss: {val_sarc_loss:.4f}\")\n",
        "        print(f\"Validation Sentiment Loss: {val_sent_loss:.4f}\")\n",
        "        print(f\"Validation Sarcasm Acc: {val_sarc_acc:.4f}\")\n",
        "        print(f\"Validation Sentiment Acc: {val_sent_acc:.4f}\")\n",
        "\n",
        "    else:\n",
        "        epoch_loss, epoch_acc = train(model, CFG['train_dataset_CFG']['task'], train_loader, optimizer, criterion, device)\n",
        "\n",
        "        val_loss, val_acc, val_f1 = validate(model, CFG['valid_dataset_CFG']['task'], val_loader, criterion, device)\n",
        "\n",
        "        if ENABLE_WANDB:\n",
        "            run.log({\n",
        "                    \"epoch/step\": epoch,\n",
        "                    \"epoch/train_loss\": epoch_loss,\n",
        "                    \"epoch/train_acc\": epoch_acc,\n",
        "                    \"epoch/val_loss\": val_loss,\n",
        "                    \"epoch/val_acc\": val_acc,\n",
        "                    \"epoch/val_f1\": val_f1\n",
        "                },\n",
        "                commit=True,\n",
        "            )\n",
        "\n",
        "        print(f\"Training Loss: {epoch_loss:.4f}\")\n",
        "        print(f\"Training Acc: {epoch_acc:.4f}\")\n",
        "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "        print(f\"Validation Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if (epoch % 30) == 0 or (epoch == CFG['epochs']):\n",
        "        checkpoint = {\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.optimizer.state_dict() if IS_MULTITASK else optimizer.state_dict(),\n",
        "            \"epoch/step\": epoch\n",
        "        }\n",
        "\n",
        "        file_name = f\"{run_id}_epoch_{epoch}.pth\"\n",
        "\n",
        "        # Saving the progress\n",
        "        file_path = os.path.join(models_root_dir, file_name)\n",
        "        torch.save(checkpoint, file_path)\n",
        "\n",
        "        print(f\"Model saved to {file_path}\")\n",
        "\n",
        "        if ENABLE_WANDB:\n",
        "            artifact = wandb.Artifact(name=run_id, type=\"model\")\n",
        "            artifact.add_file(file_path)\n",
        "\n",
        "            run.log_artifact(artifact, aliases=[\"latest\", f\"epoch_{epoch}\"])\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pfixFa0A3BJU",
      "metadata": {
        "id": "pfixFa0A3BJU"
      },
      "outputs": [],
      "source": [
        "if ENABLE_WANDB:\n",
        "    run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mIzinYigzjPP",
      "metadata": {
        "id": "mIzinYigzjPP"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7a608df",
      "metadata": {
        "id": "a7a608df"
      },
      "source": [
        "## Load a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1891f1b",
      "metadata": {
        "id": "a1891f1b"
      },
      "outputs": [],
      "source": [
        "def get_model(CFG, run_id, epoch, is_multitask, device):\n",
        "    model = MyClassifier(\n",
        "        base_model_name=CFG['model_name'],\n",
        "        classification_head_name=CFG['classification_head'],\n",
        "        num_labels=[len(v) if k in CFG['train_dataset_CFG']['task'].lower() else 0 for k,v in CFG['train_dataset_CFG']['classes'].items()],\n",
        "        multitask=is_multitask\n",
        "    ).to(device)\n",
        "\n",
        "    if not os.path.exists(models_root_dir):\n",
        "        artifact = run.use_artifact(f'elena-nespolo02-politecnico-di-torino/Figurative Analysis/{run_id}:epoch_{epoch}', type='model')\n",
        "        artifact_dir = artifact.download()\n",
        "\n",
        "        artifact_path = os.path.join(artifact_dir, run_id+f\"_epoch_{epoch}.pth\")\n",
        "\n",
        "        checkpoint = torch.load(artifact_path, map_location=device)\n",
        "\n",
        "    else:\n",
        "        file_name = f\"{run_id}_epoch_{epoch}.pth\"\n",
        "        model_path = os.path.join(models_root_dir, file_name)\n",
        "\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759cb6eb",
      "metadata": {
        "id": "759cb6eb"
      },
      "source": [
        "## For each variety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6HSdKPI5zkV9",
      "metadata": {
        "id": "6HSdKPI5zkV9"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "# Loading the trained model\n",
        "test_model = get_model(CFG, run_id, 30, IS_MULTITASK, device)\n",
        "\n",
        "for variety in ['en-AU', 'en-IN', 'en-UK']:\n",
        "    print(f\"Testing on variety: {variety}\")\n",
        "    for source, task in [('Reddit', 'sentiment'), ('Google', 'sentiment'), ('Reddit', 'sarcasm')]:\n",
        "        if task not in CFG['valid_dataset_CFG']['task'].lower():\n",
        "            continue\n",
        "\n",
        "        print(f\"\\tTesting on {source} for task: {task}\")\n",
        "\n",
        "        dataset_CFG = CFG['valid_dataset_CFG'].copy()\n",
        "        dataset_CFG['variety'] = variety\n",
        "        dataset_CFG['source'] = source\n",
        "        dataset_CFG['task'] = task\n",
        "\n",
        "        from dataset.besstie import dataset_besstie\n",
        "\n",
        "        tokenizer = model.get_tokenizer()\n",
        "        test_ds = dataset_besstie.BesstieDataSet(\n",
        "            **dataset_CFG,\n",
        "            tokenizer=tokenizer,\n",
        "            min_length=1,\n",
        "            max_length=200,\n",
        "        )\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            test_ds,\n",
        "            batch_size=CFG['batch_size'],\n",
        "            shuffle=False\n",
        "        )\n",
        "        print(f\"\\t\\tTest dataset size: {len(test_ds)}\")\n",
        "        if IS_MULTITASK:\n",
        "            optimizer = PCGrad(torch.optim.Adam(model.parameters(), lr=CFG['lr']))\n",
        "            sarc_weights = labels_count['sarcasm']\n",
        "            sent_weights = labels_count['sentiment']\n",
        "            sum_sarc = sum(sarc_weights)\n",
        "            sum_sent = sum(sent_weights)\n",
        "            sarcasm_criterion = torch.nn.CrossEntropyLoss(\n",
        "                weight=torch.tensor([sw/sum_sarc for sw in sarc_weights], dtype=torch.float).to(device)\n",
        "            )\n",
        "            sentiment_criterion = torch.nn.CrossEntropyLoss(\n",
        "                weight=torch.tensor([sw/sum_sent for sw in sent_weights], dtype=torch.float).to(device)\n",
        "            )\n",
        "            criterion = [sarcasm_criterion, sentiment_criterion] # a list of per-task losses\n",
        "\n",
        "            test_sarc_loss, test_sarc_acc, test_sarc_f1 = validate(test_model, 'sarcasm', test_loader, sarcasm_criterion, device)\n",
        "            test_sent_loss, test_sent_acc, test_sent_f1 = validate(test_model, 'sentiment', test_loader, sentiment_criterion, device)\n",
        "        else:\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
        "            weights = labels_count[list(labels_count.keys())[0]]\n",
        "            criterion = torch.nn.CrossEntropyLoss(\n",
        "                weight=torch.tensor([w/sum(weights) for w in weights], dtype=torch.float).to(device)\n",
        "            )\n",
        "\n",
        "            test_loss, test_acc, test_f1 = validate(test_model, task, test_loader, criterion, device)\n",
        "\n",
        "        results[(variety, source)] = {\n",
        "            'loss': test_loss if not IS_MULTITASK else (test_sent_loss, test_sarc_loss),\n",
        "            'acc': test_acc if not IS_MULTITASK else (test_sent_acc, test_sarc_acc),\n",
        "            'f1': test_f1 if not IS_MULTITASK else (test_sent_f1, test_sarc_f1)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f16c1991",
      "metadata": {
        "id": "f16c1991"
      },
      "outputs": [],
      "source": [
        "print(\"Final Results\")\n",
        "import seaborn as sns\n",
        "\n",
        "if not IS_MULTITASK:\n",
        "    plt.figure()\n",
        "    sns.heatmap(\n",
        "        np.array([v['f1'] for v in results.values()]).reshape(3,2),\n",
        "        annot=True,\n",
        "        xticklabels=['Reddit', 'Google'],\n",
        "        yticklabels=['en-AU', 'en-IN', 'en-UK'],\n",
        "        cmap='Blues'\n",
        "    )\n",
        "    plt.title('F1 Score Heatmap')\n",
        "else:\n",
        "    for i,task in enumerate(['sentiment', 'sarcasm']):\n",
        "        plt.figure()\n",
        "        data = np.array([v['f1'][i] for v in results.values()]).reshape(3,2)\n",
        "        sns.heatmap(\n",
        "            data,\n",
        "            annot=True,\n",
        "            xticklabels=['Reddit', 'Google'],\n",
        "            yticklabels=['en-AU', 'en-IN', 'en-UK'],\n",
        "            cmap='Blues'\n",
        "        )\n",
        "        plt.title(f'F1 Score Heatmap - {task.capitalize()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e97f30",
      "metadata": {
        "id": "88e97f30"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "58b1b893",
        "ac415049",
        "b9a1b74f",
        "a8533b24",
        "9eca838c",
        "c9174658",
        "7b79261d",
        "3e369c4f",
        "caf10d73"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01093c571a3c47179571324c9cead1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_654d918c7dac4abda2e08e6b1cb31857",
            "placeholder": "â",
            "style": "IPY_MODEL_e86ca2284ca7445db6c09add213c24ee",
            "value": "â199/199â[00:00&lt;00:00,â310.91it/s,âMaterializingâparam=pooler.dense.weight]"
          }
        },
        "02d7ca3e1394469d97b86ad5782f489e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09dab05e0fb44fb2abba4a67bddf3288": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a01a30e6a074d1b9c1f7c98007fd677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a207cae11dce41338817cab287f68ca1",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52b57208d502401f81cd936f59df5ea3",
            "value": 440449768
          }
        },
        "0db95f2e62494591864545e0307d871b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d649c5756c4941ee99412f286ab7683a",
            "placeholder": "â",
            "style": "IPY_MODEL_1cadec38201048d692f53ba92720fc19",
            "value": "tokenizer_config.json:â100%"
          }
        },
        "0e603f4b962444caab0f986e31c73499": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1974f867cab04d609e72bd793026184e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b33e59830f24c039caeca53a4a5e30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1762b91a0e44647ac5557345d33ae3d",
              "IPY_MODEL_33bbcacfca3b48cea423a9b3b36f0a87",
              "IPY_MODEL_01093c571a3c47179571324c9cead1a8"
            ],
            "layout": "IPY_MODEL_d207c873288f47d9b101b0493e13ffb9"
          }
        },
        "1c7858c358f446e18795734baacd0348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fca71463295445baabb1bac2ca3856b8",
            "placeholder": "â",
            "style": "IPY_MODEL_295543a3a8f14ee19dce613edf8d7bf6",
            "value": "model.safetensors:â100%"
          }
        },
        "1cadec38201048d692f53ba92720fc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d4c4b8bc74344edb9378daff87def4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22bb7fdc4a814ba592ef57101000caa3",
            "placeholder": "â",
            "style": "IPY_MODEL_02d7ca3e1394469d97b86ad5782f489e",
            "value": "â48.0/48.0â[00:00&lt;00:00,â812B/s]"
          }
        },
        "22bb7fdc4a814ba592ef57101000caa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e419167ce1467d9e52ff41567ab561": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295543a3a8f14ee19dce613edf8d7bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a8f02567d7c4d2da994347dec46a5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee2e851b4f144638f27d00a7c697204": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bbcacfca3b48cea423a9b3b36f0a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7beae075874f9792d05341e990a314",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cca61f2123954aed9669d2982211bf89",
            "value": 199
          }
        },
        "34858c3a39c94db9ae0e805f7c94d6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f1abe478cb04047bd841309148a7af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "417d71c4f3ef4aa88df0fd46ea82699f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46eda1d5071b463fa35bc213d57c53ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8f02567d7c4d2da994347dec46a5c6",
            "placeholder": "â",
            "style": "IPY_MODEL_55c07f47720749cd95273df5b9cf7bb5",
            "value": "vocab.txt:â100%"
          }
        },
        "49d0f3ae78ef429285f527a57e8cda08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee2e851b4f144638f27d00a7c697204",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0d14782c16d4e3e919263dc3f867fb3",
            "value": 466062
          }
        },
        "52b57208d502401f81cd936f59df5ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55c07f47720749cd95273df5b9cf7bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57ac0053e79c443e8870242bb9551ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46eda1d5071b463fa35bc213d57c53ca",
              "IPY_MODEL_f96c54650b77427fb94237f8da840b49",
              "IPY_MODEL_8a85fa67c4be47db88be5cbc95611b14"
            ],
            "layout": "IPY_MODEL_ea160e53fc1e4a8fb5b85e5353b92cf2"
          }
        },
        "59254eefe7464914954c72ce057a62a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b0ebbb1beb745ee92fd32aee4f7ac50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6485a9d1ff9b4ce289de6a0731e57e76",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e603f4b962444caab0f986e31c73499",
            "value": 570
          }
        },
        "5ce663cb119a4416946f8363dcd9a911": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e937b7caf4b44ca9a215360a44f376d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8608724097e8437f86abefd85f7a6424",
            "placeholder": "â",
            "style": "IPY_MODEL_dc374e1e36c54f5f8502e98d623e33d1",
            "value": "config.json:â100%"
          }
        },
        "6485a9d1ff9b4ce289de6a0731e57e76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "654d918c7dac4abda2e08e6b1cb31857": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d866d4d638b43078fcf85810f4a532e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6cbf7ad3a24f07a340e05df91dbcc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f09aa3a7d74c24aff26e5c8684b330": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ff411b9ca94f638fb03c5566746de4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b9950c17ba4b8fb470297b42ebc35e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b55e0f4ac8043deb25949d06632a758": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d866d4d638b43078fcf85810f4a532e",
            "placeholder": "â",
            "style": "IPY_MODEL_3f1abe478cb04047bd841309148a7af7",
            "value": "â440M/440Mâ[00:04&lt;00:00,â195MB/s]"
          }
        },
        "7c7beae075874f9792d05341e990a314": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4e264b906a44878a8ef9877d7fda77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73ff411b9ca94f638fb03c5566746de4",
            "placeholder": "â",
            "style": "IPY_MODEL_1974f867cab04d609e72bd793026184e",
            "value": "â466k/466kâ[00:00&lt;00:00,â807kB/s]"
          }
        },
        "8608724097e8437f86abefd85f7a6424": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "897473177c71477cb6e57de19ae0bbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b9950c17ba4b8fb470297b42ebc35e",
            "placeholder": "â",
            "style": "IPY_MODEL_9fb892b8da6e4c77828169594890fb2b",
            "value": "tokenizer.json:â100%"
          }
        },
        "8a85fa67c4be47db88be5cbc95611b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce663cb119a4416946f8363dcd9a911",
            "placeholder": "â",
            "style": "IPY_MODEL_a532440b02a54510867d27c995c31dfa",
            "value": "â232k/232kâ[00:00&lt;00:00,â1.43MB/s]"
          }
        },
        "95e7a4976d3444dcbefe3235b03303c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e937b7caf4b44ca9a215360a44f376d",
              "IPY_MODEL_5b0ebbb1beb745ee92fd32aee4f7ac50",
              "IPY_MODEL_b3e223141f194e55b0325f5779c04a73"
            ],
            "layout": "IPY_MODEL_24e419167ce1467d9e52ff41567ab561"
          }
        },
        "9fb892b8da6e4c77828169594890fb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a207cae11dce41338817cab287f68ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a532440b02a54510867d27c995c31dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a74d19373fcb45d593da89043bca4de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c7858c358f446e18795734baacd0348",
              "IPY_MODEL_0a01a30e6a074d1b9c1f7c98007fd677",
              "IPY_MODEL_7b55e0f4ac8043deb25949d06632a758"
            ],
            "layout": "IPY_MODEL_f7c65a0c26b349739f1778418e08aab6"
          }
        },
        "b3e223141f194e55b0325f5779c04a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c10a716e7ea1412ba3c23d7e91cf696c",
            "placeholder": "â",
            "style": "IPY_MODEL_d201bc9bb8144d55a37d9a77ae6781ba",
            "value": "â570/570â[00:00&lt;00:00,â20.1kB/s]"
          }
        },
        "c10a716e7ea1412ba3c23d7e91cf696c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12b076f6dff4111a993ece3b3670b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1762b91a0e44647ac5557345d33ae3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8dbbe229d4349709c566432e777b8b4",
            "placeholder": "â",
            "style": "IPY_MODEL_c12b076f6dff4111a993ece3b3670b34",
            "value": "Loadingâweights:â100%"
          }
        },
        "c24f00f44f7e4c61b1e5dcaa9b47ca25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0db95f2e62494591864545e0307d871b",
              "IPY_MODEL_cbb424a3057a40a898adb4d8d954fd00",
              "IPY_MODEL_1d4c4b8bc74344edb9378daff87def4f"
            ],
            "layout": "IPY_MODEL_6f6cbf7ad3a24f07a340e05df91dbcc5"
          }
        },
        "cbb424a3057a40a898adb4d8d954fd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59254eefe7464914954c72ce057a62a4",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_417d71c4f3ef4aa88df0fd46ea82699f",
            "value": 48
          }
        },
        "cca61f2123954aed9669d2982211bf89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d201bc9bb8144d55a37d9a77ae6781ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d207c873288f47d9b101b0493e13ffb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d649c5756c4941ee99412f286ab7683a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da70aa0684fe4bf8ba79bf226cb861f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_897473177c71477cb6e57de19ae0bbed",
              "IPY_MODEL_49d0f3ae78ef429285f527a57e8cda08",
              "IPY_MODEL_7f4e264b906a44878a8ef9877d7fda77"
            ],
            "layout": "IPY_MODEL_73f09aa3a7d74c24aff26e5c8684b330"
          }
        },
        "dc374e1e36c54f5f8502e98d623e33d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e86ca2284ca7445db6c09add213c24ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8dbbe229d4349709c566432e777b8b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea160e53fc1e4a8fb5b85e5353b92cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d14782c16d4e3e919263dc3f867fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7c65a0c26b349739f1778418e08aab6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96c54650b77427fb94237f8da840b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09dab05e0fb44fb2abba4a67bddf3288",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34858c3a39c94db9ae0e805f7c94d6e7",
            "value": 231508
          }
        },
        "fca71463295445baabb1bac2ca3856b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
