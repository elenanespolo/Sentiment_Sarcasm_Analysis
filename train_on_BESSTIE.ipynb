{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YBc2zrlphNWr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBc2zrlphNWr",
        "outputId": "059d0546-dcda-46d6-fb12-122fbdc69817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Sentiment_Sarcasm_Analysis' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# per trainare su Colab, impostare TRAIN_COLAB = True\n",
        "# altrimenti in locale mettere TRAIN_COLAB = False\n",
        "\n",
        "global TRAIN_COLAB\n",
        "TRAIN_COLAB = True\n",
        "\n",
        "if TRAIN_COLAB:\n",
        "    !git clone https://github.com/elenanespolo/Sentiment_Sarcasm_Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qECGVaG0hbcy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qECGVaG0hbcy",
        "outputId": "4843519d-da1a-4199-c018-232a98580cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Sentiment_Sarcasm_Analysis\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# update Colab folder after a push in the repository\n",
        "\n",
        "%cd Sentiment_Sarcasm_Analysis\n",
        "!git pull\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wKnn-MKupiXD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKnn-MKupiXD",
        "outputId": "9cd24939-372f-43e8-d746-8562025b48be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Pytorch-PCGrad' already exists and is not an empty directory.\n",
            "mv: cannot move 'Pytorch-PCGrad' to 'pcgrad_repo/Pytorch-PCGrad': Directory not empty\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WeiChengTseng/Pytorch-PCGrad\n",
        "!mv Pytorch-PCGrad pcgrad_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3fb6e87",
      "metadata": {
        "id": "b3fb6e87"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import transformers\n",
        "\n",
        "if TRAIN_COLAB:\n",
        "    from Sentiment_Sarcasm_Analysis.dataset.besstie import dataset_besstie\n",
        "    root_folder = \"Sentiment_Sarcasm_Analysis/dataset/besstie/\"\n",
        "else:\n",
        "    from dataset.besstie import dataset_besstie\n",
        "    root_folder = \"dataset/besstie/\"\n",
        "\n",
        "# NOTE: select here the split to use\n",
        "# splits = {'train': 'train.csv', 'validation': 'valid.csv'}\n",
        "splits = {'train': 'train_SS.csv', 'validation': 'valid_SS.csv'}\n",
        "if not os.path.exists(root_folder):\n",
        "    os.makedirs(root_folder)\n",
        "if not os.path.exists(os.path.join(root_folder, splits[\"train\"])) or not os.path.exists(os.path.join(root_folder, splits[\"validation\"])):\n",
        "    print(\"Downloading BESSTIE dataset...\")\n",
        "    # Login using e.g. `huggingface-cli login` to access this dataset\n",
        "    df = pd.read_csv(\"hf://datasets/unswnlporg/BESSTIE/\" + splits[\"train\"])\n",
        "    df.to_csv(os.path.join(root_folder, splits[\"train\"]), index=False)\n",
        "    df = pd.read_csv(\"hf://datasets/unswnlporg/BESSTIE/\" + splits[\"validation\"])\n",
        "    df.to_csv(os.path.join(root_folder, splits[\"validation\"]), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "470d7461",
      "metadata": {
        "id": "470d7461"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f57f88e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f57f88e",
        "outputId": "3478e8ab-47e6-49e9-e40c-3bcb22cd5499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sarcasm  sentiment\n",
            "0     2315       2361\n",
            "1      808        762\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "#TODO: add ability to choose validation subcategory of the dataset\n",
        "dataset_CFG = {\n",
        "    'dataset_name': 'BESSTIE',\n",
        "    'task': 'Sentiment-Sarcasm',\n",
        "    'variety': 'en-UK',\n",
        "    'source': 'Reddit',\n",
        "    'classes': ['0', '1']\n",
        "}\n",
        "CFG = {\n",
        "    'lr': 2e-5,\n",
        "    'start_epoch': 20,\n",
        "    'epochs': 30,\n",
        "    'batch_size': 8,\n",
        "    'max_length': 200,\n",
        "    'min_length': 1,\n",
        "    **dataset_CFG,\n",
        "    'model_name': 'bert-base-uncased',\n",
        "    'classification_head': 'cross_talk_conv', # 'linear' or 'conv' or 'lstm' or 'multi_task_conv' or 'cross_talk_conv'\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(root_folder, splits['train']))\n",
        "if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "    labels_count = pd.concat([df_train['sarcasm'].value_counts().sort_index(),df_train['sentiment'].value_counts().sort_index()], axis=1).set_axis(labels=['sarcasm', 'sentiment'], axis=1)\n",
        "else:\n",
        "    labels_count = df_train[\"label\"].value_counts().sort_index()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(labels_count)\n",
        "print(\"Using device:\", device)\n",
        "set_seed(CFG['seed'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85d7a68",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e29dc516",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiKernelConvHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        num_labels: int,\n",
        "        kernel_sizes=(2, 3, 5),\n",
        "        dropout=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList([\n",
        "            torch.nn.Conv1d(\n",
        "                in_channels=input_size,\n",
        "                out_channels=hidden_size,\n",
        "                kernel_size=k,\n",
        "                padding=k // 2\n",
        "            )\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.classifier = torch.nn.Linear(\n",
        "            hidden_size * len(kernel_sizes),\n",
        "            num_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, H, L)\n",
        "        conv_outputs = []\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = self.activation(conv(x))      # (B, C, L)\n",
        "            h = self.pool(h).squeeze(-1)       # (B, C)\n",
        "            conv_outputs.append(h)\n",
        "\n",
        "        x = torch.cat(conv_outputs, dim=1)    # (B, C * num_kernels)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "class ConvClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, num_labels: int, linear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        if linear:\n",
        "            self.conv = torch.nn.Sequential(\n",
        "                torch.nn.Conv1d(\n",
        "                    in_channels=input_size,\n",
        "                    out_channels=hidden_size,\n",
        "                    kernel_size=3,\n",
        "                    padding=1\n",
        "                ),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.AdaptiveAvgPool1d(1),  # (B, hidden_size, 1)\n",
        "                torch.nn.Flatten(),             # (B, hidden_size)\n",
        "                torch.nn.Linear(hidden_size, num_labels)\n",
        "            )\n",
        "        else:\n",
        "            self.conv = torch.nn.Sequential(\n",
        "                torch.nn.Conv1d(\n",
        "                    in_channels=input_size,\n",
        "                    out_channels=hidden_size,\n",
        "                    kernel_size=3,\n",
        "                    padding=1\n",
        "                ),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.AdaptiveAvgPool1d(1),  # (B, hidden_size, 1)\n",
        "                torch.nn.Flatten()              # (B, hidden_size)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class MultiTaskConvHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        num_sentiment_labels: int,\n",
        "        num_sarcasm_labels: int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sentiment_head = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_sentiment_labels\n",
        "        )\n",
        "\n",
        "        self.sarcasm_head = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_sarcasm_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        \"\"\"\n",
        "        sequence_output: last_hidden_state from BERT\n",
        "        shape: (batch, seq_len, hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        sentiment_logits = self.sentiment_head(sequence_output)\n",
        "        sarcasm_logits = self.sarcasm_head(sequence_output)\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": sentiment_logits,\n",
        "            \"sarcasm\": sarcasm_logits\n",
        "        }\n",
        "\n",
        "class CrossTalkHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        conv_hidden_size,\n",
        "        num_sentiment_labels,\n",
        "        num_sarcasm_labels\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=conv_hidden_size,\n",
        "            num_labels = 0,\n",
        "            linear = False\n",
        "        )\n",
        "\n",
        "        # task-specific embeddings\n",
        "        self.sentiment_embed = torch.nn.Linear(\n",
        "            conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "        self.sarcasm_embed = torch.nn.Linear(\n",
        "            conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "\n",
        "        # cross-talk layers\n",
        "        self.sentiment_fuse = torch.nn.Linear(\n",
        "            2 * conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "        self.sarcasm_fuse = torch.nn.Linear(\n",
        "            2 * conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "\n",
        "        self.sentiment_out = torch.nn.Linear(\n",
        "            conv_hidden_size, num_sentiment_labels\n",
        "        )\n",
        "        self.sarcasm_out = torch.nn.Linear(\n",
        "            conv_hidden_size, num_sarcasm_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        shared = self.encoder(sequence_output)\n",
        "\n",
        "        # first linear layer\n",
        "        sent_feat = self.sentiment_embed(shared)\n",
        "        sarc_feat = self.sarcasm_embed(shared)\n",
        "\n",
        "        # cross-talk\n",
        "        sent_feat = self.sentiment_fuse(\n",
        "            torch.cat([sent_feat, sarc_feat], dim=-1)\n",
        "        )\n",
        "        sarc_feat = self.sarcasm_fuse(\n",
        "            torch.cat([sarc_feat, sent_feat], dim=-1)\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": self.sentiment_out(sent_feat),\n",
        "            \"sarcasm\": self.sarcasm_out(sarc_feat)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e508f6ad",
      "metadata": {
        "id": "e508f6ad"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMultiKernelConvHead\u001b[39;00m(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      4\u001b[0m         input_size: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m      9\u001b[0m     ):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "def get_tokenizer_and_model(model_name:str):\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    model = transformers.AutoModel.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "def get_classification_head(method: str, input_size:int, hidden_size: int, num_labels: int):\n",
        "    if method == \"linear\":\n",
        "        return torch.nn.Linear(input_size, num_labels)\n",
        "    elif method == \"conv\":\n",
        "        return ConvClassificationHead(input_size, hidden_size, num_labels)\n",
        "    elif method == \"lstm\":\n",
        "        return torch.nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "    elif method == \"multi_conv\":\n",
        "        return MultiKernelConvHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_labels,\n",
        "            kernel_sizes=(2, 3, 5),\n",
        "            num_channels=128,\n",
        "            dropout=0.1\n",
        "        )\n",
        "    elif method == 'multi_task_conv':\n",
        "        return MultiTaskConvHead(input_size, hidden_size, num_labels, num_labels)\n",
        "    elif method == 'cross_talk_conv':\n",
        "        return CrossTalkHead(input_size, hidden_size, num_labels, num_labels)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown classification head method: {method}\")\n",
        "\n",
        "\n",
        "class MyClassifier(torch.nn.Module):\n",
        "    def __init__(self, base_model_name, classification_head_name, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tokenizer, self.base_model = get_tokenizer_and_model(base_model_name)\n",
        "        self.hidden_size = self.base_model.config.hidden_size\n",
        "        self.dropout = torch.nn.Dropout(self.base_model.config.hidden_dropout_prob)\n",
        "\n",
        "        self.classification_head_name = classification_head_name\n",
        "\n",
        "        self.classification_head = get_classification_head(\n",
        "            classification_head_name, self.hidden_size, self.hidden_size, num_labels\n",
        "        )\n",
        "\n",
        "        if classification_head_name == \"lstm\":\n",
        "            self.output_layer = torch.nn.Linear(self.hidden_size*2, num_labels)\n",
        "\n",
        "    def get_tokenizer(self) -> transformers.PreTrainedTokenizer:\n",
        "        return self.tokenizer\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = self.base_model(**inputs)\n",
        "        sequence = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        if self.classification_head_name == \"linear\":\n",
        "            cls_rep = sequence[:, 0, :]\n",
        "            logits = self.classification_head(cls_rep)\n",
        "\n",
        "        elif self.classification_head_name == \"conv\":\n",
        "            # x: (batch, seq_len, hidden_size)\n",
        "            x = sequence.transpose(1, 2)  # -> (batch, hidden_size, seq_len)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        elif self.classification_head_name == \"lstm\":\n",
        "            lstm_out, _ = self.classification_head(sequence)\n",
        "            cls_rep = lstm_out[:, 0, :]\n",
        "            logits = self.output_layer(cls_rep)\n",
        "\n",
        "        elif self.classification_head_name == 'multi_conv':\n",
        "            ## TO-DO: implement\n",
        "            logits = None\n",
        "\n",
        "        elif self.classification_head_name == 'multi_task_conv':\n",
        "            ## TO-DO: implement\n",
        "            logits = None\n",
        "\n",
        "        elif self.classification_head_name == 'cross_talk_conv':\n",
        "            x = sequence.transpose(1, 2)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e369c4f",
      "metadata": {},
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd4e582",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_SS(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_sarc_acc = 0.0\n",
        "    val_sent_acc = 0.0\n",
        "    val_sarc_loss = 0.0\n",
        "    val_sent_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = {\n",
        "                'input_ids': batch['input_ids'].to(device),\n",
        "                'attention_mask': batch['attention_mask'].to(device)\n",
        "            }\n",
        "            local_labels = batch['label'].to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            sarcasm_criterion, sentiment_criterion = criterion\n",
        "            sarc_loss = sarcasm_criterion(outputs['sarcasm'], local_labels[:,0])\n",
        "            sent_loss = sentiment_criterion(outputs['sentiment'], local_labels[:,1])\n",
        "\n",
        "            _, preds_sarc = torch.max(outputs['sarcasm'], dim=1)\n",
        "            _, preds_sent = torch.max(outputs['sentiment'], dim=1)\n",
        "\n",
        "            val_sarc_acc += torch.sum(preds_sarc == local_labels[:,0]).item()\n",
        "            val_sent_acc += torch.sum(preds_sent == local_labels[:,1]).item()\n",
        "\n",
        "            val_sarc_loss += sarc_loss.item()\n",
        "            val_sent_loss += sent_loss.item()\n",
        "\n",
        "    return val_sarc_loss / len(val_loader), val_sarc_acc / len(val_loader.dataset), val_sent_loss / len(val_loader), val_sent_acc / len(val_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2faa862",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    val_sarc_acc = 0.0\n",
        "    val_sent_acc = 0.0\n",
        "    val_sarc_loss = 0.0\n",
        "    val_sent_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = {\n",
        "                'input_ids': batch['input_ids'].to(device),\n",
        "                'attention_mask': batch['attention_mask'].to(device)\n",
        "            }\n",
        "            local_labels = batch['label'].to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "                sarcasm_criterion, sentiment_criterion = criterion\n",
        "                sarc_loss = sarcasm_criterion(outputs['sarcasm'], local_labels[:,0])\n",
        "                sent_loss = sentiment_criterion(outputs['sentiment'], local_labels[:,1])\n",
        "\n",
        "                _, preds_sarc = torch.max(outputs['sarcasm'], dim=1)\n",
        "                _, preds_sent = torch.max(outputs['sentiment'], dim=1)\n",
        "\n",
        "                val_sarc_acc += torch.sum(preds_sarc == local_labels[:,0]).item()\n",
        "                val_sent_acc += torch.sum(preds_sent == local_labels[:,1]).item()\n",
        "\n",
        "                val_sarc_loss += sarc_loss.item()\n",
        "                val_sent_loss += sent_loss.item()\n",
        "\n",
        "            else:\n",
        "                loss = criterion(outputs, local_labels)\n",
        "                _, preds = torch.max(outputs, dim=1)\n",
        "                val_acc += torch.sum(preds == local_labels).item()\n",
        "                val_loss += loss.item()\n",
        "\n",
        "    if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "        return val_sarc_loss / len(val_loader), val_sarc_acc / len(val_loader.dataset), val_sent_loss / len(val_loader), val_sent_acc / len(val_loader.dataset)\n",
        "    else:\n",
        "        return val_loss / len(val_loader), val_acc / len(val_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc87a7ea",
      "metadata": {
        "id": "bc87a7ea"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "        return validate_SS(model, val_loader, criterion, device)\n",
        "    else: \n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a57619",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "47a57619",
        "outputId": "71ed09d7-ea24-44b7-f147-84fea216512f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260103_175255-CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK' target=\"_blank\">CrossTalk</a></strong> to <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis' target=\"_blank\">https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK' target=\"_blank\">https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_metric.Metric at 0x7dd001b80980>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "run_name = \"CrossTalk\"\n",
        "run_id = f\"{run_name}_{CFG['model_name']}_{CFG['classification_head']}_{CFG['dataset_name']}_{dataset_CFG['variety']}\"\n",
        "# run_name = None\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=\"elena-nespolo02-politecnico-di-torino\",\n",
        "    project=\"Figurative Analysis\",\n",
        "    name=run_name,\n",
        "    id=run_id,\n",
        "    resume=\"allow\",\n",
        "    config=CFG,\n",
        "    tags=[CFG['dataset_name'], CFG['task'], CFG['model_name']]\n",
        ")\n",
        "\n",
        "wandb.define_metric(\"epoch/step\")\n",
        "wandb.define_metric(\"epoch/*\", step_metric=\"epoch/step\")\n",
        "\n",
        "wandb.define_metric(\"train/step\")\n",
        "wandb.define_metric(\"train/*\", step_metric=\"train/step\")\n",
        "\n",
        "wandb.define_metric(\"validate/step\")\n",
        "wandb.define_metric(\"validate/*\", step_metric=\"validate/step\")\n",
        "\n",
        "# 1f6fd3931919776776756ae7b17e69da4d5c6c3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a7b59a",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9a7b59a",
        "outputId": "25bdcab5-a7ac-458d-d1d7-2aa46328b4d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK:epoch_20', 1314.07MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:02:06.9 (10.4MB/s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:57<00:00,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3017\n",
            "Training Sentiment Loss: 0.1809\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:56<00:00,  1.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3041\n",
            "Training Sentiment Loss: 0.1869\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:56<00:00,  1.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3074\n",
            "Training Sentiment Loss: 0.1819\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:56<00:00,  1.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3141\n",
            "Training Sentiment Loss: 0.1834\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:56<00:00,  1.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3048\n",
            "Training Sentiment Loss: 0.1852\n",
            "Model saved to ./models/CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK_epoch_25.pth\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:57<00:00,  1.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3043\n",
            "Training Sentiment Loss: 0.1823\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:55<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3034\n",
            "Training Sentiment Loss: 0.1787\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:55<00:00,  1.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3074\n",
            "Training Sentiment Loss: 0.1851\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:55<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3078\n",
            "Training Sentiment Loss: 0.1860\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:55<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Sarcasm Loss: 0.3071\n",
            "Training Sentiment Loss: 0.1812\n",
            "Model saved to ./models/CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK_epoch_30.pth\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/train_sarc_loss</td><td>▁▂▄█▃▂▂▄▄▄</td></tr><tr><td>epoch/train_sent_loss</td><td>▃█▄▅▇▄▁▇▇▃</td></tr><tr><td>epoch/val_sarc_acc</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_sarc_loss</td><td>▁▃▁▃▃▂▂▁█▁</td></tr><tr><td>epoch/val_sent_acc</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_sent_loss</td><td>▅▄█▇▆█▁▃▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/step</td><td>30</td></tr><tr><td>epoch/train_sarc_loss</td><td>0.30714</td></tr><tr><td>epoch/train_sent_loss</td><td>0.18124</td></tr><tr><td>epoch/val_sarc_acc</td><td>0.7931</td></tr><tr><td>epoch/val_sarc_loss</td><td>0.28219</td></tr><tr><td>epoch/val_sent_acc</td><td>0.48276</td></tr><tr><td>epoch/val_sent_loss</td><td>1.05469</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">CrossTalk</strong> at: <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK' target=\"_blank\">https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis/runs/CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK</a><br> View project at: <a href='https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis' target=\"_blank\">https://wandb.ai/elena-nespolo02-politecnico-di-torino/Figurative%20Analysis</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260103_175255-CrossTalk_bert-base-uncased_cross_talk_conv_BESSTIE_en-UK/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tqdm\n",
        "from pcgrad_repo.pcgrad import PCGrad\n",
        "\n",
        "models_root_dir = \"./models\"\n",
        "!rm -rf {models_root_dir}\n",
        "!mkdir {models_root_dir}\n",
        "\n",
        "model_name = CFG['model_name']\n",
        "\n",
        "tokenizer, model = get_tokenizer_and_model(model_name)\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# load classifier model\n",
        "# model = transformers.BertForSequenceClassification.from_pretrained(\n",
        "#     model_name,\n",
        "#     num_labels=2\n",
        "# ).to(device)\n",
        "\n",
        "model = MyClassifier(\n",
        "    base_model_name=model_name,\n",
        "    classification_head_name=CFG['classification_head'],\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "train_ds = dataset_besstie.BesstieDataSet(\n",
        "    root_folder=root_folder,\n",
        "    file_name=splits['train'],\n",
        "    classes=dataset_CFG['classes'],\n",
        "    tokenizer=tokenizer,\n",
        "    min_length=CFG['min_length'],\n",
        "    max_length=CFG['max_length'],\n",
        "    variety=CFG['variety'],\n",
        "    source=CFG['source'],\n",
        "    task=CFG['task']\n",
        ")\n",
        "\n",
        "val_ds = dataset_besstie.BesstieDataSet(\n",
        "    root_folder=root_folder,\n",
        "    file_name=splits['validation'],\n",
        "    classes=dataset_CFG['classes'],\n",
        "    tokenizer=tokenizer,\n",
        "    min_length=CFG['min_length'],\n",
        "    max_length=CFG['max_length'],\n",
        "    variety=CFG['variety'],\n",
        "    source=CFG['source'],\n",
        "    task=CFG['task']\n",
        ")\n",
        "\n",
        "if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "    optimizer = PCGrad(torch.optim.Adam(model.parameters()))\n",
        "    sarcasm_criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count['sarcasm'].values/sum(labels_count['sarcasm']), dtype=torch.float).to(device)\n",
        "    )\n",
        "    sentiment_criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count['sentiment'].values/sum(labels_count['sentiment']), dtype=torch.float).to(device)\n",
        "    )\n",
        "    losses = [sarcasm_criterion, sentiment_criterion] # a list of per-task losses\n",
        "else:\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
        "    criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count.values/sum(labels_count), dtype=torch.float).to(device)\n",
        "    )\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "#TODO: gradient accumulation to reduce memory usage?\n",
        "# accumulation_steps = 4  # Effective batch size = batch_size * accumulation_steps\n",
        "# for i, batch in enumerate(train_dataloader):\n",
        "#     outputs = model(**batch)\n",
        "#     loss = outputs.loss / accumulation_steps\n",
        "#     loss.backward()\n",
        "#     if (i + 1) % accumulation_steps == 0:\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()\n",
        "#         model.zero_grad()\n",
        "\n",
        "# Loading form a starting point\n",
        "if CFG['start_epoch'] > 0:\n",
        "    artifact = run.use_artifact(f'elena-nespolo02-politecnico-di-torino/Figurative Analysis/{run_id}:epoch_{CFG['start_epoch']}', type='model')\n",
        "    artifact_dir = artifact.download()\n",
        "\n",
        "    artifact_path = os.path.join(artifact_dir, run_id+f\"_epoch_{CFG['start_epoch']}.pth\")\n",
        "\n",
        "    checkpoint = torch.load(artifact_path, map_location=device)\n",
        "\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    optimizer.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "for epoch in range(CFG['start_epoch']+1,CFG['epochs']+1):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_sarc_loss = 0.0\n",
        "    train_sent_loss = 0.0\n",
        "\n",
        "    print(f\"Epoch {epoch}/{CFG['epochs']}\")\n",
        "\n",
        "    pbar = tqdm.tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "\n",
        "        local_labels = batch['label'].to(device)\n",
        "        outputs = model(inputs)\n",
        "        if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "            # print(len(local_labels), len(outputs))\n",
        "            # 8 2\n",
        "            # print(type(local_labels), type(outputs))\n",
        "            # <class 'torch.Tensor'> <class 'dict'>\n",
        "            # print(local_labels.shape, outputs.keys(), outputs['sarcasm'].shape, outputs['sentiment'].shape)\n",
        "            # torch.Size([8, 2]) dict_keys(['sentiment', 'sarcasm']) torch.Size([8, 2]) torch.Size([8, 2])\n",
        "            sarc_loss = sarcasm_criterion(outputs['sarcasm'], local_labels[:,0])\n",
        "            sent_loss = sentiment_criterion(outputs['sentiment'], local_labels[:,1])\n",
        "\n",
        "            optimizer.pc_backward([sarc_loss, sent_loss])\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_sarc_loss += sarc_loss.item()\n",
        "            train_sent_loss += sent_loss.item()\n",
        "\n",
        "        else:\n",
        "            loss = criterion(outputs, local_labels)\n",
        "            print(len(local_labels), len(outputs))\n",
        "            print(type(local_labels), type(outputs))\n",
        "            # <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
        "            print(local_labels.shape, outputs.shape)\n",
        "            # torch.Size([8]) torch.Size([8, 2])\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "\n",
        "    if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "        val_sarc_loss, val_sarc_acc, val_sent_loss, val_sent_acc = validate(model, val_loader, [sarcasm_criterion, sentiment_criterion], device)\n",
        "\n",
        "        epoch_sarc_loss = train_sarc_loss / len(train_loader)\n",
        "        epoch_sent_loss = train_sent_loss / len(train_loader)\n",
        "        run.log({\n",
        "                \"epoch/step\": epoch,\n",
        "                \"epoch/train_sarc_loss\": epoch_sarc_loss,\n",
        "                \"epoch/train_sent_loss\": epoch_sent_loss,\n",
        "                \"epoch/val_sarc_loss\": val_sarc_loss,\n",
        "                \"epoch/val_sent_loss\": val_sent_loss,\n",
        "                \"epoch/val_sarc_acc\": val_sarc_acc,\n",
        "                \"epoch/val_sent_acc\": val_sent_acc\n",
        "            },\n",
        "            commit=True,\n",
        "        )\n",
        "        print(f\"Training Sarcasm Loss: {epoch_sarc_loss:.4f}\")\n",
        "        print(f\"Training Sentiment Loss: {epoch_sent_loss:.4f}\")\n",
        "    else:\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        epoch_loss = train_loss / len(train_loader)\n",
        "\n",
        "        run.log({\n",
        "                \"epoch/step\": epoch,\n",
        "                \"epoch/train_loss\": epoch_loss,\n",
        "                \"epoch/val_loss\": val_loss,\n",
        "                \"epoch/val_acc\": val_acc\n",
        "            },\n",
        "            commit=True,\n",
        "        )\n",
        "        print(f\"Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch % 5) == 0:\n",
        "        checkpoint = {\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.optimizer.state_dict(),\n",
        "            \"epoch/step\": epoch\n",
        "        }\n",
        "\n",
        "        file_name = f\"{run_id}_epoch_{epoch}.pth\"\n",
        "\n",
        "        # Saving the progress\n",
        "        file_path = os.path.join(models_root_dir, file_name)\n",
        "        torch.save(checkpoint, file_path)\n",
        "\n",
        "        print(f\"Model saved to {file_path}\")\n",
        "\n",
        "        artifact = wandb.Artifact(name=run_id, type=\"model\")\n",
        "        artifact.add_file(file_path)\n",
        "\n",
        "        run.log_artifact(artifact, aliases=[\"latest\", f\"epoch_{epoch}\"])\n",
        "\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef757b0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7ef757b0"
      },
      "outputs": [],
      "source": [
        "run.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
