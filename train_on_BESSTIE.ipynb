{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YBc2zrlphNWr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBc2zrlphNWr",
        "outputId": "059d0546-dcda-46d6-fb12-122fbdc69817"
      },
      "outputs": [],
      "source": [
        "ENABLE_WANDB = True\n",
        "TRAIN_COLAB = True\n",
        "\n",
        "if TRAIN_COLAB:\n",
        "    !git clone https://github.com/elenanespolo/Sentiment_Sarcasm_Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qECGVaG0hbcy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qECGVaG0hbcy",
        "outputId": "4843519d-da1a-4199-c018-232a98580cdf"
      },
      "outputs": [],
      "source": [
        "# update Colab folder after a push in the repository\n",
        "\n",
        "%cd Sentiment_Sarcasm_Analysis\n",
        "!git pull\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3fb6e87",
      "metadata": {
        "id": "b3fb6e87"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import transformers\n",
        "import tqdm\n",
        "\n",
        "if TRAIN_COLAB:\n",
        "    from Sentiment_Sarcasm_Analysis.dataset.besstie import dataset_besstie\n",
        "    root_folder = \"Sentiment_Sarcasm_Analysis/dataset/besstie/\"\n",
        "else:\n",
        "    from dataset.besstie import dataset_besstie\n",
        "    root_folder = \"dataset/besstie/\"\n",
        "\n",
        "# NOTE: select here the split to use\n",
        "# splits = {'train': 'train.csv', 'validation': 'valid.csv'}\n",
        "splits = {'train': 'train_SS.csv', 'validation': 'valid_SS.csv'}\n",
        "if not os.path.exists(root_folder):\n",
        "    os.makedirs(root_folder)\n",
        "if not os.path.exists(os.path.join(root_folder, splits[\"train\"])) or not os.path.exists(os.path.join(root_folder, splits[\"validation\"])):\n",
        "    print(\"Downloading BESSTIE dataset...\")\n",
        "    # Login using e.g. `huggingface-cli login` to access this dataset\n",
        "    df = pd.read_csv(\"hf://datasets/unswnlporg/BESSTIE/\" + splits[\"train\"])\n",
        "    df.to_csv(os.path.join(root_folder, splits[\"train\"]), index=False)\n",
        "    df = pd.read_csv(\"hf://datasets/unswnlporg/BESSTIE/\" + splits[\"validation\"])\n",
        "    df.to_csv(os.path.join(root_folder, splits[\"validation\"]), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "470d7461",
      "metadata": {
        "id": "470d7461"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f57f88e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f57f88e",
        "outputId": "3478e8ab-47e6-49e9-e40c-3bcb22cd5499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sarcasm  sentiment\n",
            "0     2315       2361\n",
            "1      808        762\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "#TODO: add ability to choose validation subcategory of the dataset\n",
        "dataset_CFG = {\n",
        "    'dataset_name': 'BESSTIE',\n",
        "    'task': 'Sentiment-Sarcasm',\n",
        "    'variety': 'en-UK',\n",
        "    'source': 'Reddit',\n",
        "    'classes': ['0', '1']\n",
        "}\n",
        "CFG = {\n",
        "    'lr': 2e-5,\n",
        "    'start_epoch': 20,\n",
        "    'epochs': 30,\n",
        "    'batch_size': 8,\n",
        "    'max_length': 200,\n",
        "    'min_length': 1,\n",
        "    **dataset_CFG,\n",
        "    'model_name': 'bert-base-uncased',\n",
        "    'classification_head': 'cross_talk_conv', # 'linear' or 'conv' or 'lstm' or 'multi_task_conv' or 'cross_talk_conv'\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(root_folder, splits['train']))\n",
        "if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "    labels_count = pd.concat([df_train['sarcasm'].value_counts().sort_index(),df_train['sentiment'].value_counts().sort_index()], axis=1).set_axis(labels=['sarcasm', 'sentiment'], axis=1)\n",
        "    !git clone https://github.com/WeiChengTseng/Pytorch-PCGrad\n",
        "    !mv Pytorch-PCGrad pcgrad_repo\n",
        "    from pcgrad_repo.pcgrad import PCGrad\n",
        "else:\n",
        "    labels_count = df_train[\"label\"].value_counts().sort_index()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(labels_count)\n",
        "print(\"Using device:\", device)\n",
        "set_seed(CFG['seed'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85d7a68",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e29dc516",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiKernelConvHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        num_labels: int,\n",
        "        kernel_sizes=(2, 3, 5),\n",
        "        dropout=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList([\n",
        "            torch.nn.Conv1d(\n",
        "                in_channels=input_size,\n",
        "                out_channels=hidden_size,\n",
        "                kernel_size=k,\n",
        "                padding=k // 2\n",
        "            )\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.classifier = torch.nn.Linear(\n",
        "            hidden_size * len(kernel_sizes),\n",
        "            num_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, H, L)\n",
        "        conv_outputs = []\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = self.activation(conv(x))      # (B, C, L)\n",
        "            h = self.pool(h).squeeze(-1)       # (B, C)\n",
        "            conv_outputs.append(h)\n",
        "\n",
        "        x = torch.cat(conv_outputs, dim=1)    # (B, C * num_kernels)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "class ConvClassificationHead(torch.nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, num_labels: int, linear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        if linear:\n",
        "            self.conv = torch.nn.Sequential(\n",
        "                torch.nn.Conv1d(\n",
        "                    in_channels=input_size,\n",
        "                    out_channels=hidden_size,\n",
        "                    kernel_size=3,\n",
        "                    padding=1\n",
        "                ),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.AdaptiveAvgPool1d(1),  # (B, hidden_size, 1)\n",
        "                torch.nn.Flatten(),             # (B, hidden_size)\n",
        "                torch.nn.Linear(hidden_size, num_labels)\n",
        "            )\n",
        "        else:\n",
        "            self.conv = torch.nn.Sequential(\n",
        "                torch.nn.Conv1d(\n",
        "                    in_channels=input_size,\n",
        "                    out_channels=hidden_size,\n",
        "                    kernel_size=3,\n",
        "                    padding=1\n",
        "                ),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.AdaptiveAvgPool1d(1),  # (B, hidden_size, 1)\n",
        "                torch.nn.Flatten()              # (B, hidden_size)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class MultiTaskConvHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        num_sentiment_labels: int,\n",
        "        num_sarcasm_labels: int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sentiment_head = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_sentiment_labels\n",
        "        )\n",
        "\n",
        "        self.sarcasm_head = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_sarcasm_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        \"\"\"\n",
        "        sequence_output: last_hidden_state from BERT\n",
        "        shape: (batch, seq_len, hidden_size)\n",
        "        \"\"\"\n",
        "\n",
        "        sentiment_logits = self.sentiment_head(sequence_output)\n",
        "        sarcasm_logits = self.sarcasm_head(sequence_output)\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": sentiment_logits,\n",
        "            \"sarcasm\": sarcasm_logits\n",
        "        }\n",
        "\n",
        "class CrossTalkHead(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        conv_hidden_size,\n",
        "        num_sentiment_labels,\n",
        "        num_sarcasm_labels\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = ConvClassificationHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=conv_hidden_size,\n",
        "            num_labels = 0,\n",
        "            linear = False\n",
        "        )\n",
        "\n",
        "        # task-specific embeddings\n",
        "        self.sentiment_embed = torch.nn.Linear(\n",
        "            conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "        self.sarcasm_embed = torch.nn.Linear(\n",
        "            conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "\n",
        "        # cross-talk layers\n",
        "        self.sentiment_fuse = torch.nn.Linear(\n",
        "            2 * conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "        self.sarcasm_fuse = torch.nn.Linear(\n",
        "            2 * conv_hidden_size, conv_hidden_size\n",
        "        )\n",
        "\n",
        "        self.sentiment_out = torch.nn.Linear(\n",
        "            conv_hidden_size, num_sentiment_labels\n",
        "        )\n",
        "        self.sarcasm_out = torch.nn.Linear(\n",
        "            conv_hidden_size, num_sarcasm_labels\n",
        "        )\n",
        "\n",
        "    def forward(self, sequence_output):\n",
        "        shared = self.encoder(sequence_output)\n",
        "\n",
        "        # first linear layer\n",
        "        sent_feat = self.sentiment_embed(shared)\n",
        "        sarc_feat = self.sarcasm_embed(shared)\n",
        "\n",
        "        # cross-talk\n",
        "        sent_feat = self.sentiment_fuse(\n",
        "            torch.cat([sent_feat, sarc_feat], dim=-1)\n",
        "        )\n",
        "        sarc_feat = self.sarcasm_fuse(\n",
        "            torch.cat([sarc_feat, sent_feat], dim=-1)\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"sentiment\": self.sentiment_out(sent_feat),\n",
        "            \"sarcasm\": self.sarcasm_out(sarc_feat)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e508f6ad",
      "metadata": {
        "id": "e508f6ad"
      },
      "outputs": [],
      "source": [
        "def get_tokenizer_and_model(model_name:str):\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    model = transformers.AutoModel.from_pretrained(model_name)\n",
        "    return tokenizer, model\n",
        "\n",
        "def get_classification_head(method: str, input_size:int, hidden_size: int, num_labels: int):\n",
        "    if method == \"linear\":\n",
        "        return torch.nn.Linear(input_size, num_labels)\n",
        "    elif method == \"conv\":\n",
        "        return ConvClassificationHead(input_size, hidden_size, num_labels)\n",
        "    elif method == \"lstm\":\n",
        "        return torch.nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "    elif method == \"multi_conv\":\n",
        "        return MultiKernelConvHead(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_labels=num_labels,\n",
        "            kernel_sizes=(2, 3, 5),\n",
        "            num_channels=128,\n",
        "            dropout=0.1\n",
        "        )\n",
        "    elif method == 'multi_task_conv':\n",
        "        return MultiTaskConvHead(input_size, hidden_size, num_labels, num_labels)\n",
        "    elif method == 'cross_talk_conv':\n",
        "        return CrossTalkHead(input_size, hidden_size, num_labels, num_labels)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown classification head method: {method}\")\n",
        "\n",
        "\n",
        "class MyClassifier(torch.nn.Module):\n",
        "    def __init__(self, base_model_name, classification_head_name, num_labels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tokenizer, self.base_model = get_tokenizer_and_model(base_model_name)\n",
        "        self.hidden_size = self.base_model.config.hidden_size\n",
        "        self.dropout = torch.nn.Dropout(self.base_model.config.hidden_dropout_prob)\n",
        "\n",
        "        self.classification_head_name = classification_head_name\n",
        "\n",
        "        self.classification_head = get_classification_head(\n",
        "            classification_head_name, self.hidden_size, self.hidden_size, num_labels\n",
        "        )\n",
        "\n",
        "        if classification_head_name == \"lstm\":\n",
        "            self.output_layer = torch.nn.Linear(self.hidden_size*2, num_labels)\n",
        "\n",
        "    def get_tokenizer(self) -> transformers.PreTrainedTokenizer:\n",
        "        return self.tokenizer\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = self.base_model(**inputs)\n",
        "        sequence = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        if self.classification_head_name == \"linear\":\n",
        "            cls_rep = sequence[:, 0, :]\n",
        "            logits = self.classification_head(cls_rep)\n",
        "\n",
        "        elif self.classification_head_name == \"conv\":\n",
        "            # x: (batch, seq_len, hidden_size)\n",
        "            x = sequence.transpose(1, 2)  # -> (batch, hidden_size, seq_len)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        elif self.classification_head_name == \"lstm\":\n",
        "            lstm_out, _ = self.classification_head(sequence)\n",
        "            cls_rep = lstm_out[:, 0, :]\n",
        "            logits = self.output_layer(cls_rep)\n",
        "\n",
        "        elif self.classification_head_name == 'multi_conv':\n",
        "            ## TO-DO: implement\n",
        "            logits = None\n",
        "\n",
        "        elif self.classification_head_name == 'multi_task_conv':\n",
        "            ## TO-DO: implement\n",
        "            logits = None\n",
        "\n",
        "        elif self.classification_head_name == 'cross_talk_conv':\n",
        "            x = sequence.transpose(1, 2)\n",
        "            logits = self.classification_head(x)\n",
        "\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1ee6de",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9dd2bae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_SS(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "\n",
        "    train_sarc_loss = 0.0\n",
        "    train_sent_loss = 0.0\n",
        "    train_sarc_acc = 0.0\n",
        "    train_sent_acc = 0.0\n",
        "    c1, c2 = criterion\n",
        "\n",
        "    pbar = tqdm.tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "\n",
        "        local_labels = batch['label'].to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        sarc_loss = c1(outputs['sarcasm'], local_labels[:,0])\n",
        "        sent_loss = c2(outputs['sentiment'], local_labels[:,1])\n",
        "\n",
        "        optimizer.pc_backward([sarc_loss, sent_loss])\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_sarc_loss += sarc_loss.item()\n",
        "        train_sent_loss += sent_loss.item()\n",
        "\n",
        "        _, preds_sarc = torch.max(outputs['sarcasm'], dim=1)\n",
        "        _, preds_sent = torch.max(outputs['sentiment'], dim=1)\n",
        "        train_sarc_acc += torch.sum(preds_sarc == local_labels[:,0]).item()\n",
        "        train_sent_acc += torch.sum(preds_sent == local_labels[:,1]).item()\n",
        "    \n",
        "    return train_sarc_loss / len(train_loader), train_sent_loss / len(train_loader), train_sarc_acc / (len(train_loader.dataset)), train_sent_acc / (len(train_loader.dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c33ce5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    pbar = tqdm.tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        inputs = {\n",
        "            'input_ids': batch['input_ids'].to(device),\n",
        "            'attention_mask': batch['attention_mask'].to(device)\n",
        "        }\n",
        "\n",
        "        local_labels = batch['label'].to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, local_labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        train_acc += torch.sum(preds == local_labels).item()\n",
        "        \n",
        "    return train_loss / len(train_loader), train_acc / (len(train_loader.dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e369c4f",
      "metadata": {},
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd4e582",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_SS(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_sarc_acc = 0.0\n",
        "    val_sent_acc = 0.0\n",
        "    val_sarc_loss = 0.0\n",
        "    val_sent_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = {\n",
        "                'input_ids': batch['input_ids'].to(device),\n",
        "                'attention_mask': batch['attention_mask'].to(device)\n",
        "            }\n",
        "            local_labels = batch['label'].to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            sarcasm_criterion, sentiment_criterion = criterion\n",
        "            sarc_loss = sarcasm_criterion(outputs['sarcasm'], local_labels[:,0])\n",
        "            sent_loss = sentiment_criterion(outputs['sentiment'], local_labels[:,1])\n",
        "\n",
        "            _, preds_sarc = torch.max(outputs['sarcasm'], dim=1)\n",
        "            _, preds_sent = torch.max(outputs['sentiment'], dim=1)\n",
        "\n",
        "            val_sarc_acc += torch.sum(preds_sarc == local_labels[:,0]).item()\n",
        "            val_sent_acc += torch.sum(preds_sent == local_labels[:,1]).item()\n",
        "\n",
        "            val_sarc_loss += sarc_loss.item()\n",
        "            val_sent_loss += sent_loss.item()\n",
        "\n",
        "    return val_sarc_loss / len(val_loader), val_sarc_acc / len(val_loader.dataset), val_sent_loss / len(val_loader), val_sent_acc / len(val_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2faa862",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            inputs = {\n",
        "                'input_ids': batch['input_ids'].to(device),\n",
        "                'attention_mask': batch['attention_mask'].to(device)\n",
        "            }\n",
        "            local_labels = batch['label'].to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, local_labels)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            val_acc += torch.sum(preds == local_labels).item()\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    return val_loss / len(val_loader), val_acc / len(val_loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf10d73",
      "metadata": {},
      "source": [
        "# Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a57619",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "47a57619",
        "outputId": "71ed09d7-ea24-44b7-f147-84fea216512f"
      },
      "outputs": [],
      "source": [
        "if ENABLE_WANDB:\n",
        "    import wandb\n",
        "    # NOTE: set run_name\n",
        "    run_name = \"CrossTalk\"\n",
        "    run_id = f\"{run_name}_{CFG['model_name']}_{CFG['classification_head']}_{CFG['dataset_name']}_{dataset_CFG['variety']}\"\n",
        "    # run_name = None\n",
        "\n",
        "    run = wandb.init(\n",
        "        entity=\"elena-nespolo02-politecnico-di-torino\",\n",
        "        project=\"Figurative Analysis\",\n",
        "        name=run_name,\n",
        "        id=run_id,\n",
        "        resume=\"allow\",\n",
        "        config=CFG,\n",
        "        tags=[CFG['dataset_name'], CFG['task'], CFG['model_name']]\n",
        "    )\n",
        "\n",
        "    wandb.define_metric(\"epoch/step\")\n",
        "    wandb.define_metric(\"epoch/*\", step_metric=\"epoch/step\")\n",
        "\n",
        "    wandb.define_metric(\"train/step\")\n",
        "    wandb.define_metric(\"train/*\", step_metric=\"train/step\")\n",
        "\n",
        "    wandb.define_metric(\"validate/step\")\n",
        "    wandb.define_metric(\"validate/*\", step_metric=\"validate/step\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7208179d",
      "metadata": {},
      "source": [
        "# ML loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a7b59a",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9a7b59a",
        "outputId": "25bdcab5-a7ac-458d-d1d7-2aa46328b4d9"
      },
      "outputs": [],
      "source": [
        "models_root_dir = \"./models\"\n",
        "!rm -rf {models_root_dir}\n",
        "!mkdir {models_root_dir}\n",
        "\n",
        "model_name = CFG['model_name']\n",
        "\n",
        "tokenizer, model = get_tokenizer_and_model(model_name)\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# load classifier model\n",
        "# model = transformers.BertForSequenceClassification.from_pretrained(\n",
        "#     model_name,\n",
        "#     num_labels=2\n",
        "# ).to(device)\n",
        "\n",
        "model = MyClassifier(\n",
        "    base_model_name=model_name,\n",
        "    classification_head_name=CFG['classification_head'],\n",
        "    num_labels=2\n",
        ").to(device)\n",
        "\n",
        "train_ds = dataset_besstie.BesstieDataSet(\n",
        "    root_folder=root_folder,\n",
        "    file_name=splits['train'],\n",
        "    classes=dataset_CFG['classes'],\n",
        "    tokenizer=tokenizer,\n",
        "    min_length=CFG['min_length'],\n",
        "    max_length=CFG['max_length'],\n",
        "    variety=CFG['variety'],\n",
        "    source=CFG['source'],\n",
        "    task=CFG['task']\n",
        ")\n",
        "\n",
        "val_ds = dataset_besstie.BesstieDataSet(\n",
        "    root_folder=root_folder,\n",
        "    file_name=splits['validation'],\n",
        "    classes=dataset_CFG['classes'],\n",
        "    tokenizer=tokenizer,\n",
        "    min_length=CFG['min_length'],\n",
        "    max_length=CFG['max_length'],\n",
        "    variety=CFG['variety'],\n",
        "    source=CFG['source'],\n",
        "    task=CFG['task']\n",
        ")\n",
        "\n",
        "if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "    optimizer = PCGrad(torch.optim.Adam(model.parameters()))\n",
        "    sarcasm_criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count['sarcasm'].values/sum(labels_count['sarcasm']), dtype=torch.float).to(device)\n",
        "    )\n",
        "    sentiment_criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count['sentiment'].values/sum(labels_count['sentiment']), dtype=torch.float).to(device)\n",
        "    )\n",
        "    criterion = [sarcasm_criterion, sentiment_criterion] # a list of per-task losses\n",
        "else:\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
        "    criterion = torch.nn.CrossEntropyLoss(\n",
        "        weight=torch.tensor(labels_count.values/sum(labels_count), dtype=torch.float).to(device)\n",
        "    )\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=CFG['batch_size'],\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "#TODO: gradient accumulation to reduce memory usage?\n",
        "# accumulation_steps = 4  # Effective batch size = batch_size * accumulation_steps\n",
        "# for i, batch in enumerate(train_dataloader):\n",
        "#     outputs = model(**batch)\n",
        "#     loss = outputs.loss / accumulation_steps\n",
        "#     loss.backward()\n",
        "#     if (i + 1) % accumulation_steps == 0:\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()\n",
        "#         model.zero_grad()\n",
        "\n",
        "# Loading form a starting point\n",
        "if CFG['start_epoch'] > 0 and ENABLE_WANDB:\n",
        "    artifact = run.use_artifact(f'elena-nespolo02-politecnico-di-torino/Figurative Analysis/{run_id}:epoch_{CFG['start_epoch']}', type='model')\n",
        "    artifact_dir = artifact.download()\n",
        "\n",
        "    artifact_path = os.path.join(artifact_dir, run_id+f\"_epoch_{CFG['start_epoch']}.pth\")\n",
        "\n",
        "    checkpoint = torch.load(artifact_path, map_location=device)\n",
        "\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    optimizer.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7fa1685",
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(CFG['start_epoch']+1,CFG['epochs']+1):\n",
        "\n",
        "    print(f\"Epoch {epoch}/{CFG['epochs']}\")\n",
        "\n",
        "    if dataset_CFG['task'] == 'Sentiment-Sarcasm':\n",
        "        epoch_sarc_loss, epoch_sent_loss, epoch_sarc_acc, epoch_sent_acc = train_SS(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "        val_sarc_loss, val_sarc_acc, val_sent_loss, val_sent_acc = validate_SS(model, val_loader, criterion, device)\n",
        "\n",
        "        if ENABLE_WANDB:\n",
        "            run.log({\n",
        "                    \"epoch/step\": epoch,\n",
        "                    \"epoch/train_sarc_loss\": epoch_sarc_loss,\n",
        "                    \"epoch/train_sent_loss\": epoch_sent_loss,\n",
        "                    \"epoch/train_sarc_acc\": epoch_sarc_acc,\n",
        "                    \"epoch/train_sent_acc\": epoch_sent_acc,\n",
        "                    \"epoch/val_sarc_loss\": val_sarc_loss,\n",
        "                    \"epoch/val_sent_loss\": val_sent_loss,\n",
        "                    \"epoch/val_sarc_acc\": val_sarc_acc,\n",
        "                    \"epoch/val_sent_acc\": val_sent_acc\n",
        "                },\n",
        "                commit=True,\n",
        "            )\n",
        "        print(f\"Training Sarcasm Loss: {epoch_sarc_loss:.4f}\")\n",
        "        print(f\"Training Sentiment Loss: {epoch_sent_loss:.4f}\")\n",
        "        print(f\"Training Sarcasm Acc: {epoch_sarc_acc:.4f}\")\n",
        "        print(f\"Training Sentiment Acc: {epoch_sent_acc:.4f}\")\n",
        "    else:\n",
        "        epoch_loss, epoch_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        if ENABLE_WANDB:\n",
        "            run.log({\n",
        "                    \"epoch/step\": epoch,\n",
        "                    \"epoch/train_loss\": epoch_loss,\n",
        "                    \"epoch/train_acc\": epoch_acc,\n",
        "                    \"epoch/val_loss\": val_loss,\n",
        "                    \"epoch/val_acc\": val_acc\n",
        "                },\n",
        "                commit=True,\n",
        "            )\n",
        "\n",
        "        print(f\"Training Loss: {epoch_loss:.4f}\")\n",
        "        print(f\"Training Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    if (epoch % 5) == 0 and ENABLE_WANDB:\n",
        "        checkpoint = {\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.optimizer.state_dict(),\n",
        "            \"epoch/step\": epoch\n",
        "        }\n",
        "\n",
        "        file_name = f\"{run_id}_epoch_{epoch}.pth\"\n",
        "\n",
        "        # Saving the progress\n",
        "        file_path = os.path.join(models_root_dir, file_name)\n",
        "        torch.save(checkpoint, file_path)\n",
        "\n",
        "        print(f\"Model saved to {file_path}\")\n",
        "\n",
        "        artifact = wandb.Artifact(name=run_id, type=\"model\")\n",
        "        artifact.add_file(file_path)\n",
        "\n",
        "        run.log_artifact(artifact, aliases=[\"latest\", f\"epoch_{epoch}\"])\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef757b0",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7ef757b0"
      },
      "outputs": [],
      "source": [
        "run.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
